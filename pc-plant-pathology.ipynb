{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-27T06:45:39.789479Z","iopub.execute_input":"2022-04-27T06:45:39.789787Z","iopub.status.idle":"2022-04-27T06:45:42.79281Z","shell.execute_reply.started":"2022-04-27T06:45:39.789702Z","shell.execute_reply":"2022-04-27T06:45:42.792134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\n\ntest_df = pd.read_csv(\"../input/plant-pathology-2020-fgvc7/test.csv\")\ntrain_df = pd.read_csv(\"../input/plant-pathology-2020-fgvc7/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:14:10.670194Z","iopub.execute_input":"2022-04-27T07:14:10.670722Z","iopub.status.idle":"2022-04-27T07:14:10.699766Z","shell.execute_reply.started":"2022-04-27T07:14:10.670687Z","shell.execute_reply":"2022-04-27T07:14:10.699118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:14:26.891416Z","iopub.execute_input":"2022-04-27T07:14:26.891687Z","iopub.status.idle":"2022-04-27T07:14:26.901194Z","shell.execute_reply.started":"2022-04-27T07:14:26.891659Z","shell.execute_reply":"2022-04-27T07:14:26.900424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:14:28.744586Z","iopub.execute_input":"2022-04-27T07:14:28.745241Z","iopub.status.idle":"2022-04-27T07:14:28.753956Z","shell.execute_reply.started":"2022-04-27T07:14:28.7452Z","shell.execute_reply":"2022-04-27T07:14:28.75307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['sum'] = train_df['healthy']+train_df['multiple_diseases']+train_df['rust']+train_df['scab']\n\ntrain_df[(train_df['sum']>1) | (train_df['sum']==0)]","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:15:55.94614Z","iopub.execute_input":"2022-04-27T07:15:55.946604Z","iopub.status.idle":"2022-04-27T07:15:55.96208Z","shell.execute_reply.started":"2022-04-27T07:15:55.946569Z","shell.execute_reply":"2022-04-27T07:15:55.961138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_DIR = '/kaggle/input/plant-pathology-2020-fgvc7/images'\n\ntrain_df['path'] = IMAGE_DIR+'/'+train_df['image_id']+'.jpg'\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:16:55.407977Z","iopub.execute_input":"2022-04-27T07:16:55.408797Z","iopub.status.idle":"2022-04-27T07:16:55.420067Z","shell.execute_reply.started":"2022-04-27T07:16:55.408756Z","shell.execute_reply":"2022-04-27T07:16:55.419124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_label(x):\n    if x['healthy']==1:\n        return 'healthy'\n    elif x['multiple_diseases']==1:\n        return 'multiple_diseases'\n    elif x['rust']==1:\n        return 'rust'\n    elif x['scab']==1:\n        return 'scab'\n    else : return 'None'\n\ntrain_df['label'] = train_df.apply(lambda x: get_label(x), axis=1)\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:18:47.053286Z","iopub.execute_input":"2022-04-27T07:18:47.053536Z","iopub.status.idle":"2022-04-27T07:18:47.105633Z","shell.execute_reply.started":"2022-04-27T07:18:47.053509Z","shell.execute_reply":"2022-04-27T07:18:47.104975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df.shape)\nprint(test_df.shape)\nprint(train_df['label'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:19:24.107311Z","iopub.execute_input":"2022-04-27T07:19:24.107566Z","iopub.status.idle":"2022-04-27T07:19:24.118194Z","shell.execute_reply.started":"2022-04-27T07:19:24.107538Z","shell.execute_reply":"2022-04-27T07:19:24.117218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndef show_grid_images(image_path_list, augmentor=None, ncols=4, title=None):\n    figure, axs = plt.subplots(figsize=(22,4),nrows=1, ncols=ncols)\n    for i in range(ncols):\n        image= cv2.cvtColor(cv2.imread(image_path_list[i]), cv2.COLOR_BGR2RGB)\n        if augmentor is not None:\n            image = augmentor(image=image)['image']\n        axs[i].imshow(image)\n        axs[i].axis('off')\n        axs[i].set_title(title)\n        print(image.shape)\n        \nrust_image_list = train_df[train_df['label']=='rust']['path'].iloc[:6].tolist()\nscab_image_list = train_df[train_df['label']=='scab']['path'].iloc[:6].tolist()\nhealthy_image_list = train_df[train_df['label']=='healthy']['path'].iloc[:6].tolist()\nmultiple_image_list = train_df[train_df['label']=='multiple_diseases']['path'].iloc[:6].tolist()\n\nshow_grid_images(rust_image_list, ncols=6,title='rust')\nshow_grid_images(scab_image_list, ncols=6,title='scab')\nshow_grid_images(healthy_image_list, ncols=6,title='healthy')\nshow_grid_images(multiple_image_list, ncols=6,title='multiple')","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:24:28.204208Z","iopub.execute_input":"2022-04-27T07:24:28.204496Z","iopub.status.idle":"2022-04-27T07:24:39.961622Z","shell.execute_reply.started":"2022-04-27T07:24:28.20445Z","shell.execute_reply":"2022-04-27T07:24:39.960984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import albumentations as A\n\naugmentor_01 = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.ShiftScaleRotate(scale_limit=(0.7,0.9),p=0.5,rotate_limit=30),\n    A.RandomBrightnessContrast(brightness_limit=(-0.2,0.2),contrast_limit=(-0.2,0.2),p=0.5),\n    A.Blur(p=0.2)\n])\n\nshow_grid_images(rust_image_list, augmentor = augmentor_01,ncols=6,title='rust')\nshow_grid_images(scab_image_list, augmentor = augmentor_01,ncols=6,title='scab')\nshow_grid_images(healthy_image_list, augmentor = augmentor_01,ncols=6,title='healthy')\nshow_grid_images(multiple_image_list, augmentor = augmentor_01,ncols=6,title='multiple')","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:27:50.85481Z","iopub.execute_input":"2022-04-27T07:27:50.855061Z","iopub.status.idle":"2022-04-27T07:28:04.087587Z","shell.execute_reply.started":"2022-04-27T07:27:50.855035Z","shell.execute_reply":"2022-04-27T07:28:04.086148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import Sequence\nimport sklearn\nimport cv2\n\nclass Plant_Dataset(Sequence):\n    def __init__(self, image_filenames, labels, image_size=(224,224),batch_size=64,augmentor=None, shuffle=False, pre_func=None):\n        self.image_filenames=image_filenames\n        self.labels = labels\n        self.image_size=image_size\n        self.batch_size = batch_size\n        self.augmentor = augmentor\n        self.shuffle = shuffle\n        self.pre_func = pre_func\n        \n        if self.shuffle:\n            self.on_epoch_end()\n            \n    def __len__(self):\n        return int(np.ceil(len(self.image_filenames)/self.batch_size))\n    \n    def __getitem__(self, index):\n        image_name_batch = self.image_filenames[index*self.batch_size:(index+1)*self.batch_size]\n        if self.labels is not None:\n            label_batch = self.labels[index*self.batch_size:(index+1)*self.batch_size]\n        else:\n            label_batch = None\n        image_batch = np.zeros((image_name_batch.shape[0],self.image_size[0],self.image_size[1],3),dtype='float32')\n        \n        for image_index in range(image_name_batch.shape[0]):\n            image = cv2.cvtColor(cv2.imread(image_name_batch[image_index]),cv2.COLOR_BGR2RGB)\n            if self.augmentor is not None:\n                image = self.augmentor(image=image)['image']\n            image = cv2.resize(image,(self.image_size[1],self.image_size[0]))\n            if self.pre_func is not None:\n                image = self.pre_func(image)\n                \n            image_batch[image_index]=image\n        \n        return image_batch, label_batch\n    \n    def on_epoch_end(self):\n        if self.shuffle:\n            self.image_filenames, self.labels = sklearn.utils.shuffle(self.image_filenames,self.labels)\n        else:\n            pass","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:37:20.188971Z","iopub.execute_input":"2022-04-27T07:37:20.18924Z","iopub.status.idle":"2022-04-27T07:37:25.054291Z","shell.execute_reply.started":"2022-04-27T07:37:20.189211Z","shell.execute_reply":"2022-04-27T07:37:25.053518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_df = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/sample_submission.csv')\nsample_df.head()\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:39:16.986877Z","iopub.execute_input":"2022-04-27T07:39:16.987129Z","iopub.status.idle":"2022-04-27T07:39:17.007186Z","shell.execute_reply.started":"2022-04-27T07:39:16.987102Z","shell.execute_reply":"2022-04-27T07:39:17.006535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndef get_train_valid(train_df, valid_size=0.2, random_state=2021):\n    train_path = train_df['path'].values\n    train_label = train_df[['healthy', 'multiple_diseases','rust','scab']].values\n    \n    tr_path, val_path, tr_label, val_label = train_test_split(train_path, train_label, test_size = valid_size, random_state=random_state)\n    return tr_path, val_path, tr_label, val_label","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:40:52.525778Z","iopub.execute_input":"2022-04-27T07:40:52.52605Z","iopub.status.idle":"2022-04-27T07:40:52.531674Z","shell.execute_reply.started":"2022-04-27T07:40:52.526017Z","shell.execute_reply":"2022-04-27T07:40:52.530829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.xception import preprocess_input as xcp_preprocess_input\nfrom tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess_input\n\nIMAGE_SIZE=(224,224)\nBATCH_SIZE=64\n\ntr_path, val_path, tr_label, val_label = get_train_valid(train_df, valid_size=0.2, random_state=2021)\n\ntr_ds = Plant_Dataset(tr_path, tr_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, augmentor = augmentor_01, shuffle=True, pre_func = xcp_preprocess_input)\nval_ds = Plant_Dataset(val_path, val_label, image_size=IMAGE_SIZE,batch_size=BATCH_SIZE, augmentor = None, shuffle=False, pre_func = xcp_preprocess_input)\n\ntr_image_batch = next(iter(tr_ds))[0]\nval_image_batch = next(iter(val_ds))[0]\n\nprint(tr_image_batch[0], val_image_batch[0])","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:45:07.111994Z","iopub.execute_input":"2022-04-27T07:45:07.112453Z","iopub.status.idle":"2022-04-27T07:45:12.796285Z","shell.execute_reply.started":"2022-04-27T07:45:07.112416Z","shell.execute_reply":"2022-04-27T07:45:12.795517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential , Model\nfrom tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam , RMSprop \nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\nfrom tensorflow.keras.metrics import AUC\n\nfrom tensorflow.keras.applications import Xception, ResNet50V2, EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\nfrom tensorflow.keras.applications import EfficientNetB4, EfficientNetB5, EfficientNetB6, EfficientNetB7\nimport tensorflow as tf\n\ndef create_model(model_type = 'efficientnetb0', in_shape=(224,224,3), n_classes=4):\n    input_tensor = Input(shape=in_shape)\n    \n    if model_type == 'resnet50v2':\n        base_model = tf.keras.applications.Resnet50V2(include_top=False, weight='imagenet',input_tensor=input_tensor)\n    elif model_type == 'xception':\n        base_model = tf.keras.applications.Xception(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'efficientnetb0':\n        base_model = tf.keras.applications.EfficientNetB0(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'efficientnetb1':\n        base_model = tf.keras.applications.EfficientNetB1(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'efficientnetb2':\n        base_model = tf.keras.applications.EfficientNetB2(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'efficientnetb3':\n        base_model = tf.keras.applications.EfficientNetB3(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'efficientnetb4':\n        base_model = tf.keras.applications.EfficientNetB4(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'efficientnetb5':\n        base_model = tf.keras.applications.EfficientNetB5(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'efficientnetb6':\n        base_model = tf.keras.applications.EfficientNetB6(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'efficientnetb7':\n        base_model = tf.keras.applications.EfficientNetB7(include_top=False, weights='imagenet', input_tensor=input_tensor)\n     \n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(1024, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    preds = Dense(units=n_classes, activation='softmax')(x)\n    \n    model = Model(inputs=input_tensor, outputs=preds)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-27T08:10:45.548906Z","iopub.execute_input":"2022-04-27T08:10:45.549174Z","iopub.status.idle":"2022-04-27T08:10:45.566841Z","shell.execute_reply.started":"2022-04-27T08:10:45.549132Z","shell.execute_reply":"2022-04-27T08:10:45.566073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.metrics import AUC\n\nxcp_model_01 = create_model(model_type='xception',in_shape=(224,224,3))\nxcp_model_01.compile(optimizer=Adam(0.0001),loss ='categorical_crossentropy',metrics=[AUC()])\n\nrlr_cb = ReduceLROnPlateau(monitor='val_loss',factor=0.2,patience=3,mode='min',verbose=1)\nely_cb = EarlyStopping(monitor='val_loss',patience=10, mode='min',verbose=1)\n\nhistory = xcp_model_01.fit(tr_ds, epochs=10, steps_per_epoch = int(np.ceil(tr_path.shape[0]/BATCH_SIZE)),\n                          validation_data = val_ds, validation_steps = int(np.ceil(val_path.shape[0]/BATCH_SIZE)),\n                          callbacks=[rlr_cb,ely_cb],verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T08:14:27.878244Z","iopub.execute_input":"2022-04-27T08:14:27.878577Z","iopub.status.idle":"2022-04-27T08:30:05.062221Z","shell.execute_reply.started":"2022-04-27T08:14:27.878539Z","shell.execute_reply":"2022-04-27T08:30:05.06151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_df = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/sample_submission.csv')\nsample_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T08:31:59.045072Z","iopub.execute_input":"2022-04-27T08:31:59.045694Z","iopub.status.idle":"2022-04-27T08:31:59.06803Z","shell.execute_reply.started":"2022-04-27T08:31:59.045656Z","shell.execute_reply":"2022-04-27T08:31:59.067335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_DIR = '/kaggle/input/plant-pathology-2020-fgvc7/images'\n\ntest_df = pd.read_csv('../input/plant-pathology-2020-fgvc7/test.csv')\ntest_df['path'] = IMAGE_DIR+'/'+test_df['image_id']+'.jpg'\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T08:44:16.206608Z","iopub.execute_input":"2022-04-27T08:44:16.206859Z","iopub.status.idle":"2022-04-27T08:44:16.224526Z","shell.execute_reply.started":"2022-04-27T08:44:16.206832Z","shell.execute_reply":"2022-04-27T08:44:16.223783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_path = test_df['path'].values\n\ntest_ds = Plant_Dataset(image_filenames=test_path, labels=None, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE,\n                       augmentor = None, shuffle=None, pre_func=xcp_preprocess_input)\n\npreds = xcp_model_01.predict(test_ds)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T08:44:18.683247Z","iopub.execute_input":"2022-04-27T08:44:18.68378Z","iopub.status.idle":"2022-04-27T08:45:19.007314Z","shell.execute_reply.started":"2022-04-27T08:44:18.683742Z","shell.execute_reply":"2022-04-27T08:45:19.006531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_df = pd.DataFrame(preds)\npreds_df.columns=['healthy','multiple_diseases','rust','scab']\npreds_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T08:45:38.746039Z","iopub.execute_input":"2022-04-27T08:45:38.746365Z","iopub.status.idle":"2022-04-27T08:45:38.767782Z","shell.execute_reply.started":"2022-04-27T08:45:38.746329Z","shell.execute_reply":"2022-04-27T08:45:38.76718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit_df=pd.concat([test_df['image_id'],preds_df],axis=1)\nsubmit_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T08:47:05.336022Z","iopub.execute_input":"2022-04-27T08:47:05.336574Z","iopub.status.idle":"2022-04-27T08:47:05.352888Z","shell.execute_reply.started":"2022-04-27T08:47:05.336537Z","shell.execute_reply":"2022-04-27T08:47:05.352101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit_df.to_csv('submit_01.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T08:47:27.359231Z","iopub.execute_input":"2022-04-27T08:47:27.359653Z","iopub.status.idle":"2022-04-27T08:47:27.382264Z","shell.execute_reply.started":"2022-04-27T08:47:27.359617Z","shell.execute_reply":"2022-04-27T08:47:27.381523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_submit_df(test_df, model):\n    test_path = test_df['path'].values\n    test_ds = Plant_Dataset(image_filenames=test_path, labels=None, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE,\n                           augmentor=None, shuffle=None, pre_func=xcp_preprocess_input)\n    \n    preds = model.predict(test_ds)\n    preds_df = pd.DataFrame(preds)\n    preds_df.columns=['healthy','multiple_diseases','rust','scab']\n    submit_df = pd.concat([test_df['image_id'],preds_df],axis=1)\n    return submit_df","metadata":{"execution":{"iopub.status.busy":"2022-04-27T08:51:32.253694Z","iopub.execute_input":"2022-04-27T08:51:32.25397Z","iopub.status.idle":"2022-04-27T08:51:32.259681Z","shell.execute_reply.started":"2022-04-27T08:51:32.25394Z","shell.execute_reply":"2022-04-27T08:51:32.259003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.xception import preprocess_input as xcp_preprocess_input\nfrom tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess_input\n\nIMAGE_SIZE = (320, 512)\nBATCH_SIZE = 64\n\ntr_path, val_path, tr_label, val_label = get_train_valid(train_df, valid_size=0.2, random_state=2021)\n\ntr_ds = Plant_Dataset(tr_path, tr_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n                          augmentor=augmentor_01, shuffle=True, pre_func=xcp_preprocess_input)\nval_ds = Plant_Dataset(val_path, val_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n                      augmentor=None, shuffle=False, pre_func=xcp_preprocess_input)\n\ntr_image_batch, tr_label_batch = next(iter(tr_ds))\nval_image_batch, val_label_batch = next(iter(val_ds))\nprint(tr_image_batch.shape, val_image_batch.shape, tr_label_batch.shape, val_label_batch.shape)\nprint(tr_image_batch[0], val_image_batch[0])","metadata":{"execution":{"iopub.status.busy":"2022-04-27T08:52:23.204092Z","iopub.execute_input":"2022-04-27T08:52:23.204742Z","iopub.status.idle":"2022-04-27T08:52:28.536582Z","shell.execute_reply.started":"2022-04-27T08:52:23.204707Z","shell.execute_reply":"2022-04-27T08:52:28.535697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess_input\nfrom tensorflow.keras.applications.xception import preprocess_input as xcp_preprocess_input\nimport tensorflow as tf\n\ndef lrfn_01(epoch):\n    LR_START = 1e-5\n    LR_MAX = 1e-4\n    LR_RAMPUP_EPOCHS=2\n    LR_SUSTAIN_EPOCHS=1\n    LR_STEP_DECAY=0.75\n    \n    def calc_fn(epoch):\n        if epoch < LR_RAMPUP_EPOCHS:\n            lr = (LR_MAX-LR_START)/LR_RAMPUP_EPOCHS*epoch+LR_START\n        elif epoch < LR_RAMPUP_EPOCHS+LR_SUSTAIN_EPOCHS:\n            lr = LR_MAX\n        else :\n            lr = LR_MAX*LR_STEP_DECAY**((epoch-LR_RAMPUP_EPOCHS-LR_SUSTAIN_EPCOHS)//2)\n        return lr\n    return calc_fn(epoch)\ndef lrfn_02(epoch):\n    LR_START = 1e-6\n    LR_MAX = 2e-5\n    LR_RAMPUP_EPOCHS = 2\n    LR_SUSTAIN_EPOCHS = 1\n    LR_STEP_DECAY = 0.75\n    \n    def calc_fn(epoch):\n        if epoch < LR_RAMPUP_EPOCHS:\n            lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n        elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n            lr = LR_MAX\n        else:\n            lr = LR_MAX * LR_STEP_DECAY**((epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS)//2)\n        return lr\n    \n    return calc_fn(epoch)\n\nlr01_cb = tf.keras.callbacks.LearningRateScheduler(lrfn_01, verbose=1)\nlr02_cb = tf.keras.callbacks.LearningRateScheduler(lrfn_02, verbose=1)\nrlr_cb = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, mode='min', verbose=1)\nely_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n\naugmentor_01 = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.ShiftScaleRotate(scale_limit=(0.7, 0.9), p=0.5, rotate_limit=30),\n    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.5),\n    A.Blur(p=0.2)\n])\n\nclass Config:\n    MODEL_TYPE = 'xception'\n    IMAGE_SIZE = (320,512)\n    BATCH_SIZE=32\n    N_EPOCHS=10\n    IS_FINE_TUNING=False\n    FIRST_EPOCHS=15\n    SECOND_EPOCHS=15\n    FIRST_CALLBACKS = [lr01_cb, ely_cb]\n    SECOND_CALLBACKS = [lr02_cb, ely_cb]\n    AUGMENTOR = augmentor_01\n    PRE_FUNC = xcp_preprocess_input\n    INITIAL_LR = 0.0001\n    DEBUG = True","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:08:22.87134Z","iopub.execute_input":"2022-04-27T09:08:22.871861Z","iopub.status.idle":"2022-04-27T09:08:22.8858Z","shell.execute_reply.started":"2022-04-27T09:08:22.871825Z","shell.execute_reply":"2022-04-27T09:08:22.884981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(train_df, config=Config):\n    # 학습과 검증 데이터 이미지/레이블로 분리하고 학습/검증 Dataset 생성. \n    tr_path, val_path, tr_label, val_label = get_train_valid(train_df, valid_size=0.2, random_state=2021)\n    \n    tr_ds = Plant_Dataset(tr_path, tr_label, image_size=config.IMAGE_SIZE, batch_size=config.BATCH_SIZE, \n                          augmentor=config.AUGMENTOR, shuffle=True, pre_func=config.PRE_FUNC)\n    val_ds = Plant_Dataset(val_path, val_label, image_size=config.IMAGE_SIZE, batch_size=config.BATCH_SIZE, \n                          augmentor=None, shuffle=False, pre_func=config.PRE_FUNC)\n    if config.DEBUG:\n        tr_image_batch = next(iter(tr_ds))[0]\n        val_image_batch = next(iter(val_ds))[0]\n        print(tr_image_batch.shape, val_image_batch.shape)\n        print(tr_image_batch[0], val_image_batch[0])\n        \n    # model_type인자로 들어온 모델 생성. optimizer Adam적용. \n    print('#######', config.MODEL_TYPE, ' 생성 및 학습 수행 ########')\n    model = create_model(model_type=config.MODEL_TYPE, in_shape=(config.IMAGE_SIZE[0], config.IMAGE_SIZE[1], 3), n_classes=4)\n    model.compile(optimizer=Adam(lr=config.INITIAL_LR), loss='categorical_crossentropy', metrics=[AUC()])\n    \n    # 만일 Fine tuning 일 경우 아래 로직 적용. \n    if config.IS_FINE_TUNING:\n        for layer in model.layers[:-4]:\n            layer.trainable = False\n        \n        history = model.fit(tr_ds, epochs = config.FIRST_EPOCHS, validation_data=val_ds, callbacks=config.FIRST_CALLBACKS, verbose=1)\n        \n        for layer in model.layers:\n            if config.MODEL_TYPE in 'efficientnet':\n                if not isinstance(layer, layers.BatchNormalization):\n                    layer.trainable=True\n            else:\n                layer.trainable=True\n                \n        history = model.fit(tr_ds, epochs = config.SECOND_EPOCHS, validation_data=val_ds, callbacks=config.SECOND_CALLBACKS, verbose=1)\n        \n    else:\n        history = model.fit(tr_ds, epochs = config.N_EPOCHS, validation_data=val_ds, callbacks=config.FIRST_CALLBACKS, verbose=1)\n        \n        \n    return model, history","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:08:23.397057Z","iopub.execute_input":"2022-04-27T09:08:23.397855Z","iopub.status.idle":"2022-04-27T09:08:23.410085Z","shell.execute_reply.started":"2022-04-27T09:08:23.397819Z","shell.execute_reply":"2022-04-27T09:08:23.409099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xcp_model_02, history = train_model(train_df, config=Config)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:08:23.954668Z","iopub.execute_input":"2022-04-27T09:08:23.955257Z","iopub.status.idle":"2022-04-27T09:10:10.124402Z","shell.execute_reply.started":"2022-04-27T09:08:23.955222Z","shell.execute_reply":"2022-04-27T09:10:10.123221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_submit_df(test_df, model, config=Config):\n    test_path = test_df['path'].values\n    test_ds = Planet_Dataset(image_filenames=test_path, labels=None, image_size=config.IMAGE_SIZE, batch_size= config.BATCH_SIZE,\n                            augmentor = None, shuffle=False, pre_func = config.PRE_FUNC)\n    \n    preds = model.predict(test_ds)\n    preds_df = pd.DataFrame(preds)\n    preds_df.columns=['healthy', 'multiple_diseases', 'rust', 'scab']\n    \n    submit_df = pd.concat([test_df['image_id'],preds_df],axis=1)\n    return submit_df","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:10:10.125521Z","iopub.status.idle":"2022-04-27T09:10:10.126011Z","shell.execute_reply.started":"2022-04-27T09:10:10.125761Z","shell.execute_reply":"2022-04-27T09:10:10.125787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit_df = make_submit_df(test_df, xcp_model_02, config=Config)\nsubmit_df.to_csv('submit_xcp_02.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:10:10.127191Z","iopub.status.idle":"2022-04-27T09:10:10.127745Z","shell.execute_reply.started":"2022-04-27T09:10:10.127506Z","shell.execute_reply":"2022-04-27T09:10:10.12753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}