{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-25T06:14:19.261546Z","iopub.execute_input":"2022-04-25T06:14:19.261978Z","iopub.status.idle":"2022-04-25T06:14:27.094135Z","shell.execute_reply.started":"2022-04-25T06:14:19.261864Z","shell.execute_reply":"2022-04-25T06:14:27.093133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\n\ndef make_catndog_dataframe():\n    paths=[]\n    dataset_gubuns=[]\n    label_gubuns=[]\n    \n    for dirname, _, filenames in os.walk('/kaggle/input/cat-and-dog'):\n        for filename in filenames:\n            if '.jpg' in filename:\n                file_path = dirname +'/'+filename\n                paths.append(file_path)\n                if '/training_set/' in file_path:\n                    dataset_gubuns.append('train')  \n                elif '/test_set/' in file_path:\n                    dataset_gubuns.append('test')\n                else: dataset_gubuns.append('N/A')\n\n                # 파일의 절대 경로에 dogs가 있을 경우 해당 파일은 dog 이미지 파일이고, cats일 경우는 cat 이미지 파일임. \n                if 'dogs' in file_path:\n                    label_gubuns.append('DOG')\n                elif 'cats' in file_path:\n                    label_gubuns.append('CAT')\n                else: label_gubuns.append('N/A')\n    data_df = pd.DataFrame({'path':paths, 'dataset':dataset_gubuns, 'label':label_gubuns})\n    return data_df","metadata":{"execution":{"iopub.status.busy":"2022-04-25T07:25:15.698123Z","iopub.execute_input":"2022-04-25T07:25:15.698554Z","iopub.status.idle":"2022-04-25T07:25:15.706838Z","shell.execute_reply.started":"2022-04-25T07:25:15.698518Z","shell.execute_reply":"2022-04-25T07:25:15.706064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_colwidth', 200)\ndata_df = make_catndog_dataframe()\nprint('data_df shape:', data_df.shape)\ndata_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T07:25:20.546404Z","iopub.execute_input":"2022-04-25T07:25:20.547085Z","iopub.status.idle":"2022-04-25T07:25:26.309072Z","shell.execute_reply.started":"2022-04-25T07:25:20.547048Z","shell.execute_reply":"2022-04-25T07:25:26.308383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import Sequence\nimport sklearn\nimport cv2\n\nBATCH_SIZE=64\nIMAGE_SIZE=160\n\nclass CnD_Dataset(Sequence):\n    def __init__(self, image_filenames, labels, batch_size=BATCH_SIZE,augmentor=None, pre_func = None,shuffle=False):\n        self.image_filenames= image_filenames\n        self.labels = labels\n        self.batch_size = batch_size\n        self.augmentor = augmentor\n        self.pre_func = pre_func\n        self.shuffle = shuffle\n        \n        if self.shuffle:\n            self.on_epoch_end()\n    \n    def __len__(self):\n        return int(np.ceil(len(self.labels)/BATCH_SIZE))\n    \n    def __getitem__(self, index):\n        image_name_batch = self.image_filenames[index*self.batch_size:(index+1)*self.batch_size]\n        if self.labels is not None:\n            label_batch = self.labels[index*self.batch_size:(index+1)*self.batch_size]\n        \n        image_batch = np.zeros((image_name_batch.shape[0],IMAGE_SIZE,IMAGE_SIZE,3))\n        \n        for image_index in range(image_name_batch.shape[0]):\n            image = cv2.cvtColor(cv2.imread(image_name_batch[image_index]),cv2.COLOR_BGR2RGB)\n            image = cv2.resize(image,(IMAGE_SIZE,IMAGE_SIZE))\n            \n            if self.augmentor is not None:\n                image = self.augmentor(image=image)['image']\n            if self.pre_func is not None:\n                image = self.pre_func(image)\n            \n            image_batch[image_index] = image\n        return image_batch, label_batch\n    \n    def on_epoch_end(self):\n        if(self.shuffle):\n            self.image_filenames, self.labels = sklearn.utils.shuffle(self.image_filenames,self.labels)\n        else:\n            pass","metadata":{"execution":{"iopub.status.busy":"2022-04-25T07:48:54.332239Z","iopub.execute_input":"2022-04-25T07:48:54.332488Z","iopub.status.idle":"2022-04-25T07:48:54.343773Z","shell.execute_reply.started":"2022-04-25T07:48:54.332461Z","shell.execute_reply":"2022-04-25T07:48:54.343075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndef get_train_valid_test(data_df):\n    train_df = data_df[data_df['dataset']=='train']\n    test_df = data_df[data_df['dataset']=='test']\n    \n    train_path = train_df['path'].values\n    train_label = pd.factorize(train_df['label'])[0]\n    \n    test_path = test_df['path'].values\n    test_label = pd.factorize(test_df['label'])[0]\n    \n    tr_path, val_path, tr_label, val_label = train_test_split(train_path, train_label, test_size=0.5, random_state=2021 )\n    \n    return tr_path, tr_label, val_path, val_label, test_path, test_label","metadata":{"execution":{"iopub.status.busy":"2022-04-25T07:48:54.779643Z","iopub.execute_input":"2022-04-25T07:48:54.780243Z","iopub.status.idle":"2022-04-25T07:48:54.786613Z","shell.execute_reply.started":"2022-04-25T07:48:54.78021Z","shell.execute_reply":"2022-04-25T07:48:54.785664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam , RMSprop \nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications import ResNet50V2\nfrom tensorflow.keras.applications import Xception, MobileNetV2\n\ndef create_model(model_name= 'mobilenet', verbose=False):\n    input_tensor = Input(shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n    if model_name == 'vgg16':\n        base_model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n    elif model_name == 'resnet50':\n        base_model = ResNet50V2(input_tensor=input_tensor, include_top=False, weights='imagenet')\n    elif model_name == 'xception':\n        base_model = Xception(input_tensor=input_tensor, include_top=False, weights='imagenet')\n    elif model_name == 'mobilenet':\n        base_model = MobileNetV2(input_tensor=input_tensor, include_top=False,weights='imagenet')\n        \n    bm_output = base_model.output\n    \n    x = GlobalAveragePooling2D()(bm_output)\n    if model_name != 'vgg16':\n        x = Dropout(rate=0.5)(x)\n    x = Dense(50, activation='relu', name='fc1')(x)\n    output=Dense(1, activation='sigmoid',name='output')(x)\n    \n    model = Model(inputs = input_tensor, outputs=output)\n    \n    if verbose:\n        model.summary()\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-25T07:48:55.161224Z","iopub.execute_input":"2022-04-25T07:48:55.161804Z","iopub.status.idle":"2022-04-25T07:48:55.172182Z","shell.execute_reply.started":"2022-04-25T07:48:55.161766Z","shell.execute_reply":"2022-04-25T07:48:55.171364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.mobilenet import preprocess_input as mobile_preprocess_input\n\ndef train_model(data_df, model_name, augmentor, preprocessing_func):\n    tr_path, tr_label, val_path, val_label, test_path, test_label = get_train_valid_test(data_df)\n    \n    tr_ds = CnD_Dataset(tr_path, tr_label, batch_size=BATCH_SIZE, augmentor = augmentor,shuffle=True,pre_func = preprocessing_func)\n    val_ds = CnD_Dataset(val_path, val_label, batch_size=BATCH_SIZE,augmentor = None, shuffle=False,pre_func = preprocessing_func)\n    \n    model = create_model(model_name = model_name)\n    model.compile(optimizer=Adam(0.0001),loss='binary_crossentropy', metrics=['accuracy'])\n    \n    N_EPOCHS=20\n    \n    history = model.fit(tr_ds,epochs=N_EPOCHS, steps_per_epoch = int(np.ceil(tr_path.shape[0]/BATCH_SIZE)),\n                       validation_data = val_ds, validation_steps = int(np.ceil(val_path.shape[0]/BATCH_SIZE)),verbose=1)\n    return model, history","metadata":{"execution":{"iopub.status.busy":"2022-04-25T07:48:55.617026Z","iopub.execute_input":"2022-04-25T07:48:55.617247Z","iopub.status.idle":"2022-04-25T07:48:55.624694Z","shell.execute_reply.started":"2022-04-25T07:48:55.617221Z","shell.execute_reply":"2022-04-25T07:48:55.623923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.mobilenet import preprocess_input as mobile_preprocess_input\nimport tensorflow as tf\n\ninput_df, _ = train_test_split(data_df, test_size=0.7, random_state=2021)\nmobil_model, mobile_history = train_model(input_df, 'mobilenet',None, mobile_preprocess_input)","metadata":{"execution":{"iopub.status.busy":"2022-04-25T07:48:56.309753Z","iopub.execute_input":"2022-04-25T07:48:56.310518Z","iopub.status.idle":"2022-04-25T07:52:44.098667Z","shell.execute_reply.started":"2022-04-25T07:48:56.310468Z","shell.execute_reply":"2022-04-25T07:52:44.097921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = data_df[data_df['dataset']=='test']\n\ntest_path = test_df['path'].values\ntest_label = pd.factorize(test_df['label'])[0]\n\ntest_ds = CnD_Dataset(test_path, test_label, batch_size=BATCH_SIZE,augmentor = None, shuffle=False, pre_func=mobile_preprocess_input)\nmobil_model.evaluate(test_ds)","metadata":{"execution":{"iopub.status.busy":"2022-04-25T08:01:18.108177Z","iopub.execute_input":"2022-04-25T08:01:18.108639Z","iopub.status.idle":"2022-04-25T08:01:39.369342Z","shell.execute_reply.started":"2022-04-25T08:01:18.108583Z","shell.execute_reply":"2022-04-25T08:01:39.368665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = create_model(model_name='mobilenet')\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2022-04-25T08:01:53.713158Z","iopub.execute_input":"2022-04-25T08:01:53.71341Z","iopub.status.idle":"2022-04-25T08:01:54.701434Z","shell.execute_reply.started":"2022-04-25T08:01:53.713382Z","shell.execute_reply":"2022-04-25T08:01:54.700687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.layers","metadata":{"execution":{"iopub.status.busy":"2022-04-25T08:01:59.908151Z","iopub.execute_input":"2022-04-25T08:01:59.908416Z","iopub.status.idle":"2022-04-25T08:01:59.92009Z","shell.execute_reply.started":"2022-04-25T08:01:59.90839Z","shell.execute_reply":"2022-04-25T08:01:59.919205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.layers[-4:]","metadata":{"execution":{"iopub.status.busy":"2022-04-25T08:02:02.652652Z","iopub.execute_input":"2022-04-25T08:02:02.653329Z","iopub.status.idle":"2022-04-25T08:02:02.659738Z","shell.execute_reply.started":"2022-04-25T08:02:02.653292Z","shell.execute_reply":"2022-04-25T08:02:02.658694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import layers\n\ndef train_model_fine_tune(data_df,model_name, augmentor, preprocessing_func):\n    tr_path, tr_label, val_path, val_label, test_path, test_label = get_train_valid_test(data_df)\n    \n    tr_ds = CnD_Dataset(tr_path, tr_label, batch_size=BATCH_SIZE, augmentor=augmentor, \n                          shuffle=True, pre_func=preprocessing_func)\n    val_ds = CnD_Dataset(val_path, val_label, batch_size=BATCH_SIZE, augmentor=None, \n                           shuffle=False, pre_func=preprocessing_func)\n    \n    model = create_model(model_name = model_name)\n    model.compile(optimizer=Adam(0.0001),loss='binary_crossentropy',metrics=['accuracy'])\n    \n    for layer in model.layers[:-4]:\n        layer.trainable = False\n        \n       \n    FIRST_EPOCHS = 10\n    SECOND_EPOCHS = 10\n    \n    history = model.fit(tr_ds, epochs=FIRST_EPOCHS, validation_data=val_ds, verbose=1)\n    \n    for layer in model.layers:\n        if not isinstance(layer, layer.BatchNormalization):\n            layer.trainable=True\n    \n    model.compile(optimizer=Adam(0.00001), loss='binary_crossentropy', metrics=['accuracy'])    \n    history = model.fit(tr_ds, epochs=SECOND_EPOCHS, steps_per_epoch=int(np.ceil(tr_path.shape[0]/BATCH_SIZE)), \n                       validation_data=val_ds, validation_steps=int(np.ceil(val_path.shape[0]/BATCH_SIZE)),\n                       verbose=1)\n    \n    return model, history","metadata":{"execution":{"iopub.status.busy":"2022-04-25T08:07:05.912061Z","iopub.execute_input":"2022-04-25T08:07:05.912358Z","iopub.status.idle":"2022-04-25T08:07:05.922495Z","shell.execute_reply.started":"2022-04-25T08:07:05.912329Z","shell.execute_reply":"2022-04-25T08:07:05.921596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobile_model_tuned, mobile_tuned_history = train_model_fine_tune(input_df,'mobilenet',None, mobile_preprocess_input)","metadata":{"execution":{"iopub.status.busy":"2022-04-25T08:07:06.619002Z","iopub.execute_input":"2022-04-25T08:07:06.619239Z","iopub.status.idle":"2022-04-25T08:09:05.815469Z","shell.execute_reply.started":"2022-04-25T08:07:06.619214Z","shell.execute_reply":"2022-04-25T08:09:05.814487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobile_model_tuned.evaluate(test_ds)","metadata":{"execution":{"iopub.status.busy":"2022-04-25T08:09:05.816506Z","iopub.status.idle":"2022-04-25T08:09:05.817445Z","shell.execute_reply.started":"2022-04-25T08:09:05.817191Z","shell.execute_reply":"2022-04-25T08:09:05.817217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}