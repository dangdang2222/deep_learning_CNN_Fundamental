{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-11T05:03:04.035051Z","iopub.execute_input":"2022-04-11T05:03:04.035387Z","iopub.status.idle":"2022-04-11T05:03:04.062861Z","shell.execute_reply.started":"2022-04-11T05:03:04.035285Z","shell.execute_reply":"2022-04-11T05:03:04.062224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os","metadata":{"execution":{"iopub.status.busy":"2022-04-11T05:03:20.446321Z","iopub.execute_input":"2022-04-11T05:03:20.446686Z","iopub.status.idle":"2022-04-11T05:03:20.450574Z","shell.execute_reply.started":"2022-04-11T05:03:20.446642Z","shell.execute_reply":"2022-04-11T05:03:20.44987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D\nfrom tensorflow.keras.models import Model\n\ninput_tensor = Input(shape=(28,28,1))\nx = Conv2D(filters=4,kernel_size=3,strides=1, padding='same',activation='relu')(input_tensor)\nprint('x type : ',type(x), 'x : ',x)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T05:11:48.476288Z","iopub.execute_input":"2022-04-11T05:11:48.476976Z","iopub.status.idle":"2022-04-11T05:11:50.653652Z","shell.execute_reply.started":"2022-04-11T05:11:48.476938Z","shell.execute_reply":"2022-04-11T05:11:50.652997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_tensor = Input(shape=(28,28,1))\nx = Conv2D(filters=16, kernel_size=3, strides=1, padding='same',activation='relu')(input_tensor)\nx = MaxPooling2D(2)(x)\nprint(x)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T05:13:21.97563Z","iopub.execute_input":"2022-04-11T05:13:21.976194Z","iopub.status.idle":"2022-04-11T05:13:21.997229Z","shell.execute_reply.started":"2022-04-11T05:13:21.976154Z","shell.execute_reply":"2022-04-11T05:13:21.99656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_tensor = Input(shape=(28,28,1))\nx = Conv2D(filters=32, kernel_size=3,strides=1, padding='same',activation='relu')(input_tensor)\nx = Conv2D(filters=64, kernel_size=3, activation='relu')(x)\nx = MaxPooling2D(2)(x)\n\nmodel = Model(inputs=input_tensor, outputs=x)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T05:16:38.27233Z","iopub.execute_input":"2022-04-11T05:16:38.273037Z","iopub.status.idle":"2022-04-11T05:16:38.309616Z","shell.execute_reply.started":"2022-04-11T05:16:38.272999Z","shell.execute_reply":"2022-04-11T05:16:38.30889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, Flatten\n\ninput_tensor = Input(shape=(28,28,1))\nx = Conv2D(filters=32, kernel_size=3, strides=1, padding='same',activation='relu')(input_tensor)\nx = Conv2D(filters=64, kernel_size=3, activation='relu')(x)\nx = MaxPooling2D(2)(x)\n\nx = Flatten()(x)\nx = Dense(100, activation = 'relu')(x)\noutput = Dense(10, activation = 'softmax')(x)\n\nmodel = Model(inputs=input_tensor, outputs=output)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T05:26:02.232448Z","iopub.execute_input":"2022-04-11T05:26:02.233135Z","iopub.status.idle":"2022-04-11T05:26:02.283219Z","shell.execute_reply.started":"2022-04-11T05:26:02.233098Z","shell.execute_reply":"2022-04-11T05:26:02.282434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.datasets import fashion_mnist\nimport numpy as np\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\n# 전체 6만개 데이터 중, 5만개는 학습 데이터용, 1만개는 테스트 데이터용으로 분리\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n\ndef get_preprocessed_data(images, labels):\n    \n    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n    images = np.array(images/255.0, dtype=np.float32)\n    labels = np.array(labels, dtype=np.float32)\n    \n    return images, labels\n\n# 0 ~ 1사이값 float32로 변경하는 함수 호출 한 뒤 OHE 적용 \ndef get_preprocessed_ohe(images, labels):\n    images, labels = get_preprocessed_data(images, labels)\n    # OHE 적용 \n    oh_labels = to_categorical(labels)\n    return images, oh_labels\n\n# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환 \ndef get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경 및 OHE 적용. \n    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n    \n    # 학습 데이터를 검증 데이터 세트로 다시 분리\n    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n    \n    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels ) \n\n\n# Fashion MNIST 데이터 재 로딩 및 전처리 적용하여 학습/검증/데이터 세트 생성. \n\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\nprint(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)\n(tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n    get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\nprint(tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T05:29:06.125245Z","iopub.execute_input":"2022-04-11T05:29:06.125818Z","iopub.status.idle":"2022-04-11T05:29:09.208839Z","shell.execute_reply.started":"2022-04-11T05:29:06.125778Z","shell.execute_reply":"2022-04-11T05:29:09.208077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.metrics import Accuracy\n\nmodel.compile(optimizer=Adam(0.001), loss = 'categorical_crossentropy', metrics = ['accuracy'])\nhitory = model.fit(x=tr_images , y=tr_oh_labels, batch_size=128, epochs=30, validation_data=(val_images, val_oh_labels))\n","metadata":{"execution":{"iopub.status.busy":"2022-04-11T05:31:41.197055Z","iopub.execute_input":"2022-04-11T05:31:41.197337Z","iopub.status.idle":"2022-04-11T05:33:03.892832Z","shell.execute_reply.started":"2022-04-11T05:31:41.197307Z","shell.execute_reply":"2022-04-11T05:33:03.892047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\ndef show_history(history):\n    plt.plot(history.history['accuracy'],label = 'train')\n    plt.plot(history.history['val_accuracy'], label='valid')\n    plt.legend()\n\n#show_history(hitory)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T05:41:33.340353Z","iopub.execute_input":"2022-04-11T05:41:33.341053Z","iopub.status.idle":"2022-04-11T05:41:33.347859Z","shell.execute_reply.started":"2022-04-11T05:41:33.341014Z","shell.execute_reply":"2022-04-11T05:41:33.346747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(test_images, test_oh_labels, batch_size=256, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T05:35:44.821651Z","iopub.execute_input":"2022-04-11T05:35:44.821934Z","iopub.status.idle":"2022-04-11T05:35:45.224915Z","shell.execute_reply.started":"2022-04-11T05:35:44.821903Z","shell.execute_reply":"2022-04-11T05:35:45.224192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#flatten할때 파라미터가 넘 많아져서 overfitting 발생함 --> dropout으로 해결\n\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout\n\ninput_tensor = Input(shape=(28, 28, 1))\nx = Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu')(input_tensor)\nx = Conv2D(filters=64, kernel_size=3, activation='relu')(x)\nx = MaxPooling2D(2)(x)\n\nx = Flatten()(x)\nx = Dropout(rate=0.5)(x)\nx = Dense(100, activation='relu')(x)\noutput = Dense(10, activation = 'softmax')(x)\n\nmodel = Model(inputs = input_tensor, outputs = output)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T05:38:33.526312Z","iopub.execute_input":"2022-04-11T05:38:33.526866Z","iopub.status.idle":"2022-04-11T05:38:33.576528Z","shell.execute_reply.started":"2022-04-11T05:38:33.526829Z","shell.execute_reply":"2022-04-11T05:38:33.57586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=Adam(0.001), loss = 'categorical_crossentropy', metrics=['accuracy'])\nhistory = model. fit(x=tr_images, y=tr_oh_labels, batch_size=128, epochs=30, validation_data=(val_images, val_oh_labels))","metadata":{"execution":{"iopub.status.busy":"2022-04-11T05:39:31.123254Z","iopub.execute_input":"2022-04-11T05:39:31.123934Z","iopub.status.idle":"2022-04-11T05:40:44.085714Z","shell.execute_reply.started":"2022-04-11T05:39:31.123897Z","shell.execute_reply":"2022-04-11T05:40:44.08503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_history(history)\nmodel.evaluate(test_images, test_oh_labels, batch_size=256,verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T05:41:36.443763Z","iopub.execute_input":"2022-04-11T05:41:36.444016Z","iopub.status.idle":"2022-04-11T05:41:36.889555Z","shell.execute_reply.started":"2022-04-11T05:41:36.443988Z","shell.execute_reply":"2022-04-11T05:41:36.888889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, GlobalAveragePooling2D\n\ndef create_model():\n    input_tensor = Input(shape=(28,28,1))\n    x = Conv2D(filters=32, kernel_size=3, strides=1, padding='same',activation='relu')(input_tensor)\n    x = Conv2D(filters=64, kernel_size=3, activation='relu')(x)\n    x = MaxPooling2D(2)(x)\n    \n    x = Flatten()(x)\n    x = Dropout(rate=0.5)(x)\n    x = Dense(200, activation='relu')(x)\n    x = Dropout(rate=0.2)(x)\n    output = Dense(10, activation='softmax')(x)\n    \n    model = Model(inputs=input_tensor, outputs=output)\n    model.summary()\n    \n    return model\n\nmodel = create_model()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T05:45:50.71287Z","iopub.execute_input":"2022-04-11T05:45:50.713135Z","iopub.status.idle":"2022-04-11T05:45:50.959235Z","shell.execute_reply.started":"2022-04-11T05:45:50.713106Z","shell.execute_reply":"2022-04-11T05:45:50.958575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(x=tr_images, y=tr_oh_labels, batch_size=128, epochs=30, validation_data=(val_images, val_oh_labels))\nshow_history(history)\nmodel.evaluate(test_images, test_oh_labels, batch_size=256, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T05:46:10.149167Z","iopub.execute_input":"2022-04-11T05:46:10.14945Z","iopub.status.idle":"2022-04-11T05:47:29.028048Z","shell.execute_reply.started":"2022-04-11T05:46:10.14942Z","shell.execute_reply":"2022-04-11T05:47:29.027409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n\nprint('before reshape:', train_images.shape, test_images.shape)\ntrain_images = np.reshape(train_images, (60000, 28, 28, 1))\ntest_images = np.reshape(test_images, (10000, 28, 28, 1))\nprint('after reshape:', train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)\n\n(tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n    get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\nprint(tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T05:48:14.850935Z","iopub.execute_input":"2022-04-11T05:48:14.851191Z","iopub.status.idle":"2022-04-11T05:48:15.593025Z","shell.execute_reply.started":"2022-04-11T05:48:14.851159Z","shell.execute_reply":"2022-04-11T05:48:15.592013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D\nfrom tensorflow.keras.models import Model\n\ninput_tensor = Input(shape=(5,5,1))\nx = Conv2D(filters = 1, kernel_size=3, strides=1)(input_tensor)\nprint('x.shape:',x.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:28:05.442886Z","iopub.execute_input":"2022-04-11T06:28:05.443158Z","iopub.status.idle":"2022-04-11T06:28:05.465424Z","shell.execute_reply.started":"2022-04-11T06:28:05.443128Z","shell.execute_reply":"2022-04-11T06:28:05.464746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_tensor = Input(shape=(5, 5, 1))\nx = Conv2D(filters=1, kernel_size=3, strides=1, padding='same')(input_tensor)\nprint('x.shape:', x.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:29:13.286426Z","iopub.execute_input":"2022-04-11T06:29:13.286968Z","iopub.status.idle":"2022-04-11T06:29:13.303884Z","shell.execute_reply.started":"2022-04-11T06:29:13.286932Z","shell.execute_reply":"2022-04-11T06:29:13.303031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import ZeroPadding2D\n\ninput_tensor = Input(shape=(5,5,1))\npadded_input = ZeroPadding2D(padding=1)(input_tensor)\nprint(padded_input.shape)\nx = Conv2D(filters=1, kernel_size=3, strides=1)(padded_input)\nprint(x.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:30:41.544172Z","iopub.execute_input":"2022-04-11T06:30:41.544464Z","iopub.status.idle":"2022-04-11T06:30:41.564763Z","shell.execute_reply.started":"2022-04-11T06:30:41.544432Z","shell.execute_reply":"2022-04-11T06:30:41.56405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_tensor = Input(shape=(5, 5, 1))\nx = Conv2D(filters=1, kernel_size=3, strides=2)(input_tensor)\nprint('x.shape:', x.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:30:59.939756Z","iopub.execute_input":"2022-04-11T06:30:59.940004Z","iopub.status.idle":"2022-04-11T06:30:59.958076Z","shell.execute_reply.started":"2022-04-11T06:30:59.939976Z","shell.execute_reply":"2022-04-11T06:30:59.957422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_tensor = Input(shape=(5, 5, 1))\npadded_input = ZeroPadding2D(padding=1)(input_tensor)\nprint('shape after padding:', padded_input.shape)\nx = Conv2D(filters=1, kernel_size=3, strides=2)(padded_input)\nprint('x.shape:', x.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:31:40.084112Z","iopub.execute_input":"2022-04-11T06:31:40.084372Z","iopub.status.idle":"2022-04-11T06:31:40.104609Z","shell.execute_reply.started":"2022-04-11T06:31:40.084341Z","shell.execute_reply":"2022-04-11T06:31:40.103941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_tensor = Input(shape=(6, 6, 1))\npadded_input = ZeroPadding2D(padding=1)(input_tensor)\nx = Conv2D(filters=1, kernel_size=3, strides=2, padding='valid')(padded_input)\nprint('x.shape:', x.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:35:35.665867Z","iopub.execute_input":"2022-04-11T06:35:35.666189Z","iopub.status.idle":"2022-04-11T06:35:35.687715Z","shell.execute_reply.started":"2022-04-11T06:35:35.666156Z","shell.execute_reply":"2022-04-11T06:35:35.687025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_tensor = Input(shape=(223, 223, 1))\nx = MaxPooling2D(2)(input_tensor)\nprint('x.shape:', x.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:36:42.898112Z","iopub.execute_input":"2022-04-11T06:36:42.898901Z","iopub.status.idle":"2022-04-11T06:36:42.909794Z","shell.execute_reply.started":"2022-04-11T06:36:42.898793Z","shell.execute_reply":"2022-04-11T06:36:42.909046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Dense, Conv2D, Dropout, Flatten, Activation, MaxPooling2D, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n\nIMAGE_SIZE=32\n\ninput_tensor = Input(shape=(IMAGE_SIZE,IMAGE_SIZE,3))\nx = Conv2D(filters=32, kernel_size=(5,5),padding='valid',activation='relu')(input_tensor)\nx = Conv2D(filters=32, kernel_size=(3,3),padding='same',activation='relu')(x)\nx = MaxPooling2D(pool_size=(2,2))(x)\n\nx = Conv2D(filters=64, kernel_size=(3,3),padding='same',activation='relu')(input_tensor)\nx = Conv2D(filters=64, kernel_size=(3,3),padding='same')(x)\nx = Activation('relu')(x)\nx = MaxPooling2D(pool_size=2)(x)\n\nx = Conv2D(filters=128, kernel_size=(3,3),padding='same',activation='relu')(input_tensor)\nx = Conv2D(filters=128, kernel_size=(3,3),padding='same',activation='relu')(x)\nx = MaxPooling2D(pool_size=2)(x)\n\nx = Flatten(name='flatten')(x)\nx = Dropout(rate=0.5)(x)\nx = Dense(300, activation='relu',name='fc1')(x)\nx = Dropout(rate=0.3)(x)\noutput = Dense(10, activation='softmax',name='output')(x)\n\nmodel = Model(inputs = input_tensor, outputs=output)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T07:29:48.376033Z","iopub.execute_input":"2022-04-11T07:29:48.376352Z","iopub.status.idle":"2022-04-11T07:29:48.530519Z","shell.execute_reply.started":"2022-04-11T07:29:48.376314Z","shell.execute_reply":"2022-04-11T07:29:48.529852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}