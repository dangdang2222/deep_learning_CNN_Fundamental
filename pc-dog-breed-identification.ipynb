{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-25T11:42:59.779797Z","iopub.execute_input":"2022-04-25T11:42:59.780389Z","iopub.status.idle":"2022-04-25T11:42:59.80376Z","shell.execute_reply.started":"2022-04-25T11:42:59.78028Z","shell.execute_reply":"2022-04-25T11:42:59.803028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar","metadata":{"execution":{"iopub.status.busy":"2022-04-25T11:43:00.833877Z","iopub.execute_input":"2022-04-25T11:43:00.834491Z","iopub.status.idle":"2022-04-25T11:45:10.019032Z","shell.execute_reply.started":"2022-04-25T11:43:00.834451Z","shell.execute_reply":"2022-04-25T11:45:10.018157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls; tar -xvf images.tar","metadata":{"execution":{"iopub.status.busy":"2022-04-25T11:45:14.303178Z","iopub.execute_input":"2022-04-25T11:45:14.303492Z","iopub.status.idle":"2022-04-25T11:45:17.219389Z","shell.execute_reply.started":"2022-04-25T11:45:14.30346Z","shell.execute_reply":"2022-04-25T11:45:17.218488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls; pwd","metadata":{"execution":{"iopub.status.busy":"2022-04-25T11:53:40.770425Z","iopub.execute_input":"2022-04-25T11:53:40.771175Z","iopub.status.idle":"2022-04-25T11:53:41.425026Z","shell.execute_reply.started":"2022-04-25T11:53:40.771133Z","shell.execute_reply":"2022-04-25T11:53:41.424158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cd /kaggle/working/Images;ls","metadata":{"execution":{"iopub.status.busy":"2022-04-25T11:54:19.210145Z","iopub.execute_input":"2022-04-25T11:54:19.210466Z","iopub.status.idle":"2022-04-25T11:54:19.870194Z","shell.execute_reply.started":"2022-04-25T11:54:19.210432Z","shell.execute_reply":"2022-04-25T11:54:19.869338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/working/Images'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-04-25T11:55:30.548003Z","iopub.execute_input":"2022-04-25T11:55:30.548507Z","iopub.status.idle":"2022-04-25T11:55:33.2723Z","shell.execute_reply.started":"2022-04-25T11:55:30.548469Z","shell.execute_reply":"2022-04-25T11:55:33.271678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_DIR = '/kaggle/working/Images'\n\ndef make_dogbreed_dataframe(image_dir = IMAGE_DIR):\n    paths=[]\n    label_gubuns=[]\n    for dirname,_,filenames in os.walk(image_dir):\n        for filename in filenames:\n            if '.jpg' in filename:\n                file_path = dirname+'/'+filename\n                paths.append(file_path)\n                start_pos = file_path.find('/',20)\n                end_pos = file_path.rfind('/')\n                imsi_breed = file_path[start_pos+1:end_pos]\n                breed = imsi_breed[imsi_breed.find('-')+1:]\n                label_gubuns.append(breed)\n    \n    data_df = pd.DataFrame({'path':paths, 'label':label_gubuns})\n    return data_df","metadata":{"execution":{"iopub.status.busy":"2022-04-25T13:14:50.40375Z","iopub.execute_input":"2022-04-25T13:14:50.404019Z","iopub.status.idle":"2022-04-25T13:14:50.410824Z","shell.execute_reply.started":"2022-04-25T13:14:50.40399Z","shell.execute_reply":"2022-04-25T13:14:50.409757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df = make_dogbreed_dataframe('/kaggle/working/Images')\ndata_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T13:14:50.810743Z","iopub.execute_input":"2022-04-25T13:14:50.811008Z","iopub.status.idle":"2022-04-25T13:14:50.881202Z","shell.execute_reply.started":"2022-04-25T13:14:50.81098Z","shell.execute_reply":"2022-04-25T13:14:50.880373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T13:14:51.566636Z","iopub.execute_input":"2022-04-25T13:14:51.5669Z","iopub.status.idle":"2022-04-25T13:14:51.578995Z","shell.execute_reply.started":"2022-04-25T13:14:51.566872Z","shell.execute_reply":"2022-04-25T13:14:51.57811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.figure(figsize=(26,4))\nsns.countplot(data=data_df,x='label')\nplt.xticks(rotation=90)","metadata":{"execution":{"iopub.status.busy":"2022-04-25T13:14:52.285918Z","iopub.execute_input":"2022-04-25T13:14:52.286308Z","iopub.status.idle":"2022-04-25T13:14:54.166909Z","shell.execute_reply.started":"2022-04-25T13:14:52.286273Z","shell.execute_reply":"2022-04-25T13:14:54.166234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\n\ndef show_grid_images(image_path_list, ncols=8, title=None):\n    figure, axs = plt.subplots(figsize=(22,4),nrows=1, ncols=ncols)\n    for i in range(ncols):\n        image = cv2.cvtColor(cv2.imread(image_path_list[i]),cv2.COLOR_BGR2RGB)\n        axs[i].imshow(image)\n        axs[i].set_title(title)","metadata":{"execution":{"iopub.status.busy":"2022-04-25T13:14:54.168648Z","iopub.execute_input":"2022-04-25T13:14:54.169127Z","iopub.status.idle":"2022-04-25T13:14:54.175684Z","shell.execute_reply.started":"2022-04-25T13:14:54.169089Z","shell.execute_reply":"2022-04-25T13:14:54.174975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"breed_image_list_01 = data_df[data_df['label']=='Staffordshire_bullterrier']['path'].iloc[:6].tolist()\nbreed_image_list_02 = data_df[data_df['label']=='American_Staffordshire_terrier']['path'].iloc[:6].tolist()\n\nshow_grid_images(breed_image_list_01, ncols=6, title='S')\nshow_grid_images(breed_image_list_02, ncols=6, title='A')","metadata":{"execution":{"iopub.status.busy":"2022-04-25T13:14:55.564082Z","iopub.execute_input":"2022-04-25T13:14:55.564342Z","iopub.status.idle":"2022-04-25T13:14:57.603475Z","shell.execute_reply.started":"2022-04-25T13:14:55.564312Z","shell.execute_reply":"2022-04-25T13:14:57.60247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df['label'].value_counts().index.tolist()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T13:14:59.126214Z","iopub.execute_input":"2022-04-25T13:14:59.126474Z","iopub.status.idle":"2022-04-25T13:14:59.138017Z","shell.execute_reply.started":"2022-04-25T13:14:59.126445Z","shell.execute_reply":"2022-04-25T13:14:59.137347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"breed_list = data_df['label'].value_counts().index.tolist()\n\nfor iter_cnt, breed in enumerate(breed_list):\n    breed_image_list = data_df[data_df['label']==breed]['path'].iloc[:6].tolist()\n    show_grid_images(breed_image_list, ncols=6, title=breed)\n    if iter_cnt==4: \n        break","metadata":{"execution":{"iopub.status.busy":"2022-04-25T13:15:00.20712Z","iopub.execute_input":"2022-04-25T13:15:00.207841Z","iopub.status.idle":"2022-04-25T13:15:04.807805Z","shell.execute_reply.started":"2022-04-25T13:15:00.207805Z","shell.execute_reply":"2022-04-25T13:15:04.807006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import albumentations as A\n\nimsi_augmentor = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.ShiftScaleRotate(p=0.5),\n    A.RandomBrightnessContrast(brightness_limit=(-0.2,0.2), contrast_limit=(-0.2,0.2),p=0.5),\n    A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5)\n])\n\ndef show_grid_images(image_path_list, augmentor=None, ncols=4, title=None):\n    figure,axs=plt.subplots(figsize=(22,4),nrows=1, ncols=ncols)\n    for i in range(ncols):\n        image = cv2.cvtColor(cv2.imread(image_path_list[i]),cv2.COLOR_BGR2RGB)\n        if augmentor:\n            image = augmentor(image=image)['image']\n        image = cv2.resize(image,(224,224))\n        \n        axs[i].imshow(image)\n        axs[i].axis('off')\n        \n        axs[i].set_title(title)\n        \nbreed_image_list_01 = data_df[data_df['label']=='Staffordshire_bullterrier']['path'].iloc[:6].tolist()\nshow_grid_images(breed_image_list_01, augmentor=None, ncols=6, title='original')\nshow_grid_images(breed_image_list_01, augmentor = imsi_augmentor, ncols=6, title='augmented')","metadata":{"execution":{"iopub.status.busy":"2022-04-25T13:15:04.809354Z","iopub.execute_input":"2022-04-25T13:15:04.80972Z","iopub.status.idle":"2022-04-25T13:15:05.778905Z","shell.execute_reply.started":"2022-04-25T13:15:04.809676Z","shell.execute_reply":"2022-04-25T13:15:05.778125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_df, test_df = train_test_split(data_df, test_size=0.4, stratify=data_df['label'],random_state=2021)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-25T13:15:06.950863Z","iopub.execute_input":"2022-04-25T13:15:06.951747Z","iopub.status.idle":"2022-04-25T13:15:06.991585Z","shell.execute_reply.started":"2022-04-25T13:15:06.951707Z","shell.execute_reply":"2022-04-25T13:15:06.990889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df['label'].value_counts())\nprint(test_df['label'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-04-25T13:15:07.940519Z","iopub.execute_input":"2022-04-25T13:15:07.941258Z","iopub.status.idle":"2022-04-25T13:15:07.952476Z","shell.execute_reply.started":"2022-04-25T13:15:07.941218Z","shell.execute_reply":"2022-04-25T13:15:07.951773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_path = train_df['path'].values\ntrain_label = pd.get_dummies(train_df['label']).values\n\ntr_path, val_path, tr_label, val_label = train_test_split(train_path, train_label, stratify=train_label, test_size=0.2, random_state=0)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-25T13:15:08.721166Z","iopub.execute_input":"2022-04-25T13:15:08.721716Z","iopub.status.idle":"2022-04-25T13:15:10.588978Z","shell.execute_reply.started":"2022-04-25T13:15:08.721678Z","shell.execute_reply":"2022-04-25T13:15:10.588227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import Sequence\nimport sklearn\nimport cv2\n\nBATCH_SIZE=64\nIMAGE_SIZE=224\n\nclass Breed_Dataset(Sequence):\n    def __init__(self, image_filenames,labels,image_size=IMAGE_SIZE, batch_size=BATCH_SIZE,augmentor=None, shuffle=False, pre_func=None):\n        self.image_filenames= image_filenames\n        self.labels = labels\n        self.image_size = image_size\n        self.batch_size=batch_size\n        self.augmentor = augmentor\n        self.pre_func = pre_func\n        self.shuffle = shuffle\n        if self.shuffle:\n            self.on_epoch_end()\n            \n    def __len__(self):\n        return int(np.ceil(len(self.labels)/self.batch_size))\n    \n    def __getitem__(self, index):\n        image_name_batch = self.image_filenames[index*self.batch_size:(index+1)*self.batch_size]\n        if self.labels is not None:\n            label_batch = self.labels[index*self.batch_size:(index+1)*self.batch_size]\n        image_batch = np.zeros((image_name_batch.shape[0],self.image_size,self.image_size,3))\n        \n        for image_index in range(image_name_batch.shape[0]):\n            image = cv2.cvtColor(cv2.imread(image_name_batch[image_index]),cv2.COLOR_BGR2RGB)\n            if self.augmentor is not None:\n                image = self.augmentor(image=image)['image']\n            image = cv2.resize(image,(self.image_size,self.image_size))\n            \n            if self.pre_func is not None:\n                image = self.pre_func(image)\n            image_batch[image_index] = image\n        return image_batch, label_batch\n    \n    def on_epoch_end(self):\n        if self.shuffle:\n            self.image_filenames, self.labels = sklearn.utils.shuffle(self.image_filenames, self.labels)\n        else: \n            pass\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2022-04-25T13:15:11.604956Z","iopub.execute_input":"2022-04-25T13:15:11.605208Z","iopub.status.idle":"2022-04-25T13:15:11.617608Z","shell.execute_reply.started":"2022-04-25T13:15:11.605181Z","shell.execute_reply":"2022-04-25T13:15:11.616507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import albumentations as A\n\naugmentor_light = A.Compose([\n    A.HorizontalFlip(p=0.5)\n])","metadata":{"execution":{"iopub.status.busy":"2022-04-25T13:15:13.210819Z","iopub.execute_input":"2022-04-25T13:15:13.211603Z","iopub.status.idle":"2022-04-25T13:15:13.215638Z","shell.execute_reply.started":"2022-04-25T13:15:13.211558Z","shell.execute_reply":"2022-04-25T13:15:13.214671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess_input\nfrom tensorflow.keras.applications.xception import preprocess_input as xcp_preprocess_input\n\ntr_ds = Breed_Dataset(tr_path, tr_label,image_size=IMAGE_SIZE,batch_size=BATCH_SIZE,augmentor = augmentor_light,shuffle=True, pre_func= xcp_preprocess_input )\nval_ds = Breed_Dataset(val_path, val_label, image_size=IMAGE_SIZE,batch_size=BATCH_SIZE,augmentor=None, shuffle=None, pre_func=xcp_preprocess_input)\n\ntr_image_batch = next(iter(tr_ds))[0]\nval_image_batch = next(iter(val_ds))[0]\n\nprint(tr_image_batch.shape, val_image_batch.shape)\nprint(tr_image_batch[:1])\nprint(val_image_batch[:1])","metadata":{"execution":{"iopub.status.busy":"2022-04-25T13:15:24.927204Z","iopub.execute_input":"2022-04-25T13:15:24.92746Z","iopub.status.idle":"2022-04-25T13:15:25.44017Z","shell.execute_reply.started":"2022-04-25T13:15:24.927431Z","shell.execute_reply":"2022-04-25T13:15:25.439271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\n\ntr_ds = Breed_Dataset(tr_path, tr_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, augmentor=augmentor_light, shuffle=True, pre_func=xcp_preprocess_input)\nval_ds = Breed_Dataset(val_path, val_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, augmentor=None, shuffle=False, pre_func=xcp_preprocess_input)\n\nstart = time.time()\nfor value1, value2 in iter(tr_ds):\n    end=time.time()\n    print(end-start)\n    start=end","metadata":{"execution":{"iopub.status.busy":"2022-04-25T13:15:25.841676Z","iopub.execute_input":"2022-04-25T13:15:25.842341Z","iopub.status.idle":"2022-04-25T13:15:31.698644Z","shell.execute_reply.started":"2022-04-25T13:15:25.842305Z","shell.execute_reply":"2022-04-25T13:15:31.697457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Input, Conv2D, Dropout, Flatten, Activation, MaxPooling2D,GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import RMSprop, Adam\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint,LearningRateScheduler\nfrom tensorflow.keras.applications import Xception, ResNet50V2, EfficientNetB0,EfficientNetB1\nfrom tensorflow.keras.applications import MobileNet\nimport tensorflow as tf\n\ndef create_model(model_type = 'xception', in_shape=(224,224,3),n_classes=120):\n    input_tensor=Input(shape=in_shape)\n    \n    if model_type=='resnet50v2':\n        base_model = tf.keras.applications.ResNet50V2(input_tensor = input_tensor,include_top=False, weights='imagenet')\n    elif model_type =='xception':\n        base_model = tf.keras.applications.Xception(input_tensor = input_tensor, include_top=False, weights='imagenet')\n    elif model_type =='efficientnetb0':\n        base_model = tf.keras.applications.EfficientNetB0(input_tensor = input_tensor, include_top=False, weights='imagenet')\n    elif model_type == 'efficientnetb1':\n        base_model = tf.keras.applications.EfficientNetB1(input_tensor=input_tensor, include_top=False, weights='imagenet')\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(1024,activation='relu')(x)\n    x = Dropout(0.5)(x)\n    preds = Dense(units=n_classes, activation='softmax')(x)\n    \n    model = Model(inputs=input_tensor, outputs=preds)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-25T13:15:33.650108Z","iopub.execute_input":"2022-04-25T13:15:33.650646Z","iopub.status.idle":"2022-04-25T13:15:33.663564Z","shell.execute_reply.started":"2022-04-25T13:15:33.650609Z","shell.execute_reply":"2022-04-25T13:15:33.662853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import Sequence\nimport sklearn \nimport cv2\n\nimport albumentations as A\n\nIMAGE_DIR = '/kaggle/working/Images' \n\ndef make_dogbreed_dataframe(image_dir=IMAGE_DIR):\n    paths=[]\n    label_gubuns=[]\n    for dirname,_,filenames in os.walk(image_dir):\n        for filename in filenames:\n            if '.jpg' in filename:\n                file_path = dirname + '/' + filename\n                paths.append(file_path)\n                start_pos = file_path.find('/',20)\n                end_pos = file_path.rfind('/')\n                imsi_breed = file_path[start_pos+1:end_pos]\n                breed = imsi_breed[imsi_breed.find('-')+1:]\n                label_gubuns.append(breed)\n    data_df = pd.DataFrame({'path':paths,'label':label_gubuns})\n    return data_df\n\ndef get_train_valid(train_df, valid_size=0.2, random_state=2021):\n    train_path = train_df['path'].values\n    train_label = pd.get_dummies(train_df['label']).values\n    \n    tr_path, val_path, tr_label, val_label = train_test_split(train_path, train_label, test_size=valid_size, random_state=random_state)\n    \n    return tr_path, val_path, tr_label, val_label\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-25T13:22:59.930834Z","iopub.execute_input":"2022-04-25T13:22:59.931097Z","iopub.status.idle":"2022-04-25T13:22:59.940858Z","shell.execute_reply.started":"2022-04-25T13:22:59.931068Z","shell.execute_reply":"2022-04-25T13:22:59.940104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_EPOCHS = 30\n\ndef train_model(model_type, train_df, initial_lr =0.001, augmentor = None, input_pre_func=None):\n    tr_path, val_path, tr_label, val_label = get_train_valid(train_df,valid_size=0.2,random_state=2021)\n    tr_ds = Breed_Dataset(tr_path, tr_label,image_size=IMAGE_SIZE,batch_size=BATCH_SIZE,augmentor = augmentor,shuffle=True, pre_func= input_pre_func )\n    val_ds = Breed_Dataset(val_path, val_label, image_size=IMAGE_SIZE,batch_size=BATCH_SIZE,augmentor=None, shuffle=None, pre_func=input_pre_func)\n    \n    model=create_model(model_type=model_type)\n    model.compile(optimizer=Adam(lr=initial_lr),loss='categorical_crossentropy',metrics=['accuracy'])\n    \n    rlr_cb = ReduceLROnPlateau(monitor='val_loss',factor=0.2, patience=3, mode='min',verbose=1)\n    ely_cb = EarlyStopping(monitor='val_loss',patience=10, mode='min',verbose=1)\n    \n    history = model.fit(tr_ds, epochs = N_EPOCHS, validation_data=val_ds, callbacks=[rlr_cb,ely_cb],verbose=1)\n    \n    return model, history\n\nIMAGE_DIR = '/kaggle/working/Images'\n\ndata_df = make_dogbreed_dataframe(image_dir=IMAGE_DIR)\ntrain_df, test_df = train_test_split(data_df, test_size=0.4, stratify=data_df['label'],random_state=2021)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-25T13:24:36.038132Z","iopub.execute_input":"2022-04-25T13:24:36.038549Z","iopub.status.idle":"2022-04-25T13:24:36.150735Z","shell.execute_reply.started":"2022-04-25T13:24:36.038498Z","shell.execute_reply":"2022-04-25T13:24:36.149925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.xception import preprocess_input as xcp_preprocess_input\n\nxception_model, xception_history = train_model(model_type='xception',train_df=train_df,initial_lr = 0.001, augmentor=augmentor_light,input_pre_func = xcp_preprocess_input)","metadata":{"execution":{"iopub.status.busy":"2022-04-25T13:24:37.594147Z","iopub.execute_input":"2022-04-25T13:24:37.594805Z","iopub.status.idle":"2022-04-25T14:03:44.928972Z","shell.execute_reply.started":"2022-04-25T13:24:37.59476Z","shell.execute_reply":"2022-04-25T14:03:44.928191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_path = test_df['path'].values\ntest_label = pd.get_dummies(test_df['label']).values\n\ntest_df['gt_class']= np.argmax(test_label, axis=1)\n\ntest_ds = Breed_Dataset(test_path, test_label, image_size=IMAGE_SIZE, batch_size = BATCH_SIZE, augmentor = None, shuffle=False, pre_func=xcp_preprocess_input)\nxception_model.evaluate(test_ds)","metadata":{"execution":{"iopub.status.busy":"2022-04-25T14:06:01.593165Z","iopub.execute_input":"2022-04-25T14:06:01.593949Z","iopub.status.idle":"2022-04-25T14:07:23.861098Z","shell.execute_reply.started":"2022-04-25T14:06:01.593899Z","shell.execute_reply":"2022-04-25T14:07:23.860404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_result = xception_model.predict(test_ds,steps=int(np.ceil(len(test_label)/BATCH_SIZE)))\npredict_class = np.argmax(predict_result, axis=1)\ntest_df['xcp_pred_class']=predict_class\n\ntest_df[test_df['gt_class']!=test_df['xcp_pred_class']]['label'].value_counts()\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.figure(figsize=(26,4))\nplt.xticks(rotation=90)\nwrong_result_df = test_df[test_df['gt_class']!=test_df['xcp_pred_class']]\nsns.countplot(data=wrong_result_df, x='label')","metadata":{"execution":{"iopub.status.busy":"2022-04-25T14:07:58.62517Z","iopub.execute_input":"2022-04-25T14:07:58.625547Z","iopub.status.idle":"2022-04-25T14:08:42.654988Z","shell.execute_reply.started":"2022-04-25T14:07:58.625487Z","shell.execute_reply":"2022-04-25T14:08:42.654359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_grid_images(image_path_list, augmentor=None, ncols=4, title=None):\n    figure, axs = plt.subplots(figsize=(22,4), nrows=1, ncols=ncols)\n    for i in range(ncols):\n        image = cv2.cvtColor(cv2.imread(image_path_list[i]),cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image,(224,224))\n        if augmentor is not None:\n            image = augmentor(image=image)['image']\n        axs[i].imshow(image)\n        axs[i].axis('off')\n        axs[i].set_title(title)\n        \nbreed_image_list_01 = data_df[data_df['label']=='Siberian_husky']['path'].iloc[:6].tolist()\nbreed_image_list_02 = data_df[data_df['label']=='Eskimo_dog']['path'].iloc[:6].tolist()\n\nshow_grid_images(breed_image_list_01,ncols=6, title='S')\nshow_grid_images(breed_image_list_02,ncols=6, title='E')","metadata":{"execution":{"iopub.status.busy":"2022-04-25T14:09:07.439385Z","iopub.execute_input":"2022-04-25T14:09:07.439906Z","iopub.status.idle":"2022-04-25T14:09:08.343881Z","shell.execute_reply.started":"2022-04-25T14:09:07.439864Z","shell.execute_reply":"2022-04-25T14:09:08.342593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess_input\n\neffb0_model_t1, effb0_history_t1 = train_model(model_type='efficientnetb0',train_df=train_df,initial_lr=0.0001, augmentor=augmentor_light,input_pre_func = eff_preprocess_input)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_path = test_df['path'].values\ntest_label = pd.get_dummies(test_df['label']).values\n\ntest_df = Breed_Dataset(test_path, test_label, image_size=IMAGE_SIZE, batch_size= BATCH_SIZE, augmentor=None, shuffle=False, pre_func=eff_preprocess_input)\neffb0_model_t1.evaluate(test_df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_result = effb0_model_t1.predict(test_df, steps=int(np.ceil(len(test_label)/BATCH_SIZE)))\npredict_class = np.argmax(predict_result, axis=1)\ntest_df['effb0_t1_pred_class']= predict_class\n\ntest_df[test_df['gt_class']!=test_df['effb0_t1_pred_class']]['label'].value_counts()","metadata":{},"execution_count":null,"outputs":[]}]}