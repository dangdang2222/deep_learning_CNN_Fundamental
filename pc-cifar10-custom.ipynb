{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-11T07:40:05.069617Z","iopub.execute_input":"2022-04-11T07:40:05.070314Z","iopub.status.idle":"2022-04-11T07:40:05.080671Z","shell.execute_reply.started":"2022-04-11T07:40:05.070214Z","shell.execute_reply":"2022-04-11T07:40:05.079973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os","metadata":{"execution":{"iopub.status.busy":"2022-04-11T07:40:05.087272Z","iopub.execute_input":"2022-04-11T07:40:05.087753Z","iopub.status.idle":"2022-04-11T07:40:05.096249Z","shell.execute_reply.started":"2022-04-11T07:40:05.087723Z","shell.execute_reply":"2022-04-11T07:40:05.095291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.datasets import cifar10\n\n(train_images, train_labels),(test_images, test_labels) = cifar10.load_data()\nprint(train_images.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T07:40:05.102328Z","iopub.execute_input":"2022-04-11T07:40:05.102803Z","iopub.status.idle":"2022-04-11T07:40:07.764918Z","shell.execute_reply.started":"2022-04-11T07:40:05.102761Z","shell.execute_reply":"2022-04-11T07:40:07.764061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NAMES = np.array(['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck'])\nprint(train_labels[:10])","metadata":{"execution":{"iopub.status.busy":"2022-04-11T07:40:07.767621Z","iopub.execute_input":"2022-04-11T07:40:07.768711Z","iopub.status.idle":"2022-04-11T07:40:07.775803Z","shell.execute_reply.started":"2022-04-11T07:40:07.768666Z","shell.execute_reply":"2022-04-11T07:40:07.774681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport cv2\n%matplotlib inline\n\ndef show_images(images, labels, ncols=8):\n    figure, axs = plt.subplots(figsize=(22,6),nrows=1, ncols=ncols)\n    for i in range(ncols):\n        axs[i].imshow(images[i])\n        label = labels[i].squeeze()\n        axs[i].set_title(NAMES[int(label)])\n        \nshow_images(train_images[:8],train_labels[:8],ncols=8)\nshow_images(train_images[8:16], train_labels[8:16], ncols=8)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T07:40:07.777106Z","iopub.execute_input":"2022-04-11T07:40:07.777737Z","iopub.status.idle":"2022-04-11T07:40:09.286265Z","shell.execute_reply.started":"2022-04-11T07:40:07.777696Z","shell.execute_reply":"2022-04-11T07:40:09.285584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_preprocessed_data(images, labels):\n    images = np.array(images/255.0, dtype = np.float32)\n    labels = np.array(labels, dtype=np.float32)\n    \n    return images, labels\n\ntrain_images, train_labels = get_preprocessed_data(train_images, train_labels)\ntest_images, test_labels = get_preprocessed_data(test_images, test_labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T07:40:09.28802Z","iopub.execute_input":"2022-04-11T07:40:09.288805Z","iopub.status.idle":"2022-04-11T07:40:10.01529Z","shell.execute_reply.started":"2022-04-11T07:40:09.288765Z","shell.execute_reply":"2022-04-11T07:40:10.014536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images[0,:,:,:]","metadata":{"execution":{"iopub.status.busy":"2022-04-11T07:40:10.018024Z","iopub.execute_input":"2022-04-11T07:40:10.018592Z","iopub.status.idle":"2022-04-11T07:40:10.028812Z","shell.execute_reply.started":"2022-04-11T07:40:10.018555Z","shell.execute_reply":"2022-04-11T07:40:10.028023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels = train_labels.squeeze()\ntest_labels = test_labels.squeeze()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T07:40:10.029976Z","iopub.execute_input":"2022-04-11T07:40:10.030729Z","iopub.status.idle":"2022-04-11T07:40:10.0362Z","shell.execute_reply.started":"2022-04-11T07:40:10.030688Z","shell.execute_reply":"2022-04-11T07:40:10.035202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Dense, Conv2D, Dropout, Flatten, Activation, MaxPooling2D, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n\nIMAGE_SIZE=32\n\ninput_tensor = Input(shape=(IMAGE_SIZE,IMAGE_SIZE,3))\nx = Conv2D(filters=32, kernel_size=(5,5),padding='valid',activation='relu')(input_tensor)\nx = Conv2D(filters=32, kernel_size=(3,3),padding='same',activation='relu')(x)\nx = MaxPooling2D(pool_size=(2,2))(x)\n\nx = Conv2D(filters=64, kernel_size=(3,3),padding='same',activation='relu')(x)\nx = Conv2D(filters=64, kernel_size=(3,3),padding='same')(x)\nx = Activation('relu')(x)\nx = MaxPooling2D(pool_size=2)(x)\n\nx = Conv2D(filters=128, kernel_size=(3,3),padding='same',activation='relu')(x)\nx = Conv2D(filters=128, kernel_size=(3,3),padding='same',activation='relu')(x)\nx = MaxPooling2D(pool_size=2)(x)\n\nx = Flatten(name='flatten')(x)\nx = Dropout(rate=0.5)(x)\nx = Dense(300, activation='relu',name='fc1')(x)\nx = Dropout(rate=0.3)(x)\noutput = Dense(10, activation='softmax',name='output')(x)\n\nmodel = Model(inputs = input_tensor, outputs=output)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T07:40:10.037721Z","iopub.execute_input":"2022-04-11T07:40:10.038068Z","iopub.status.idle":"2022-04-11T07:40:11.08943Z","shell.execute_reply.started":"2022-04-11T07:40:10.038031Z","shell.execute_reply":"2022-04-11T07:40:11.088673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer=Adam(),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\nhistory = model.fit(x=train_images,y=train_labels, batch_size=64,epochs=30,validation_split=0.15)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T07:40:52.771502Z","iopub.execute_input":"2022-04-11T07:40:52.772295Z","iopub.status.idle":"2022-04-11T07:43:16.408588Z","shell.execute_reply.started":"2022-04-11T07:40:52.772256Z","shell.execute_reply":"2022-04-11T07:43:16.407769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\ndef show_history(history):\n    plt.figure(figsize=(6,6))\n    plt.yticks(np.arange(0,1,0.05))\n    plt.plot(history.history['accuracy'],label = 'train')\n    plt.plot(history.history['val_accuracy'], label='valid')\n    plt.legend()\n    \nshow_history(history)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T08:09:44.222994Z","iopub.execute_input":"2022-04-11T08:09:44.223282Z","iopub.status.idle":"2022-04-11T08:09:44.456735Z","shell.execute_reply.started":"2022-04-11T08:09:44.22325Z","shell.execute_reply":"2022-04-11T08:09:44.45607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(test_images, test_labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T08:10:16.047066Z","iopub.execute_input":"2022-04-11T08:10:16.04732Z","iopub.status.idle":"2022-04-11T08:10:17.264881Z","shell.execute_reply.started":"2022-04-11T08:10:16.047291Z","shell.execute_reply":"2022-04-11T08:10:17.264199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#4차원\npreds = model.predict(np.expand_dims(test_images[0],axis=0))\nprint(preds.shape)\nprint(preds)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T08:11:50.276464Z","iopub.execute_input":"2022-04-11T08:11:50.277112Z","iopub.status.idle":"2022-04-11T08:11:50.417331Z","shell.execute_reply.started":"2022-04-11T08:11:50.277075Z","shell.execute_reply":"2022-04-11T08:11:50.416578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model.predict(test_images[:32], batch_size=32)\nprint(preds.shape)\nprint(preds)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T08:13:35.179247Z","iopub.execute_input":"2022-04-11T08:13:35.180066Z","iopub.status.idle":"2022-04-11T08:13:35.234287Z","shell.execute_reply.started":"2022-04-11T08:13:35.180019Z","shell.execute_reply":"2022-04-11T08:13:35.232753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_class = np.argmax(preds, axis=1)\nprint(predicted_class)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T08:14:31.28316Z","iopub.execute_input":"2022-04-11T08:14:31.283436Z","iopub.status.idle":"2022-04-11T08:14:31.289257Z","shell.execute_reply.started":"2022-04-11T08:14:31.283403Z","shell.execute_reply":"2022-04-11T08:14:31.288283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_images(test_images[:8],predicted_class[:8],ncols=8)\nshow_images(test_images[8:16], predicted_class[8:16], ncols=8)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T08:15:15.642021Z","iopub.execute_input":"2022-04-11T08:15:15.642347Z","iopub.status.idle":"2022-04-11T08:15:17.120894Z","shell.execute_reply.started":"2022-04-11T08:15:15.642313Z","shell.execute_reply":"2022-04-11T08:15:17.12023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os \nnumbers = np.random.normal(loc=0.0, scale=1, size=[100,100])\nprint(numbers)\nprint(numbers.mean())\nprint(numbers.std())\nprint(numbers.sum())","metadata":{"execution":{"iopub.status.busy":"2022-04-11T12:01:15.74675Z","iopub.execute_input":"2022-04-11T12:01:15.747295Z","iopub.status.idle":"2022-04-11T12:01:15.755055Z","shell.execute_reply.started":"2022-04-11T12:01:15.747255Z","shell.execute_reply":"2022-04-11T12:01:15.754249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fan_in = 20\nfan_out = 15\nscale_value = np.sqrt(2/(fan_in + fan_out))\nprint('scale:',scale_value)\nweights = np.random.normal(loc=0.0, scale= scale_value, size=[100,100])\nprint(weights)\nprint(weights.mean(), weights.std(), weights.sum())","metadata":{"execution":{"iopub.status.busy":"2022-04-11T12:07:42.125854Z","iopub.execute_input":"2022-04-11T12:07:42.126426Z","iopub.status.idle":"2022-04-11T12:07:42.137819Z","shell.execute_reply.started":"2022-04-11T12:07:42.126381Z","shell.execute_reply":"2022-04-11T12:07:42.136862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fan_in = 10\nfan_out = 8\nlimit = np.sqrt(6/(fan_in+fan_out))\nprint(limit)\nweights = np.random.uniform(-1*limit, limit, size=[100,100])\nprint(weights)\nprint(weights.mean(), weights.std(), weights.sum())","metadata":{"execution":{"iopub.status.busy":"2022-04-11T12:09:09.203972Z","iopub.execute_input":"2022-04-11T12:09:09.204508Z","iopub.status.idle":"2022-04-11T12:09:09.213375Z","shell.execute_reply.started":"2022-04-11T12:09:09.20447Z","shell.execute_reply":"2022-04-11T12:09:09.212535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fan_in = 10\nscale_value = np.sqrt(2/(fan_in))\nprint(scale_value)\nweights = np.random.normal(loc=0.0, scale = scale_value, size=(100,100))\nprint(weights)\nprint(weights.mean(), weights.std(), weights.sum())","metadata":{"execution":{"iopub.status.busy":"2022-04-11T12:13:13.356532Z","iopub.execute_input":"2022-04-11T12:13:13.356787Z","iopub.status.idle":"2022-04-11T12:13:13.367342Z","shell.execute_reply.started":"2022-04-11T12:13:13.356756Z","shell.execute_reply":"2022-04-11T12:13:13.365891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"fan_in = 10\nlimit = np.sqrt(6/fan_in)\nweights = np.random.uniform(limit*-1, limit, size=(100,100))\nprint(weights)\nprint(weights.mean(), weights.std(), weights.sum())","metadata":{"execution":{"iopub.status.busy":"2022-04-11T12:13:47.92668Z","iopub.execute_input":"2022-04-11T12:13:47.926949Z","iopub.status.idle":"2022-04-11T12:13:47.934694Z","shell.execute_reply.started":"2022-04-11T12:13:47.926919Z","shell.execute_reply":"2022-04-11T12:13:47.933929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.utils import to_categorical\n\ndef get_preprocessed_data(images, labels):\n    \n    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n    images = np.array(images/255.0, dtype=np.float32)\n    labels = np.array(labels, dtype=np.float32)\n    labels = labels.squeeze()\n    \n    return images, labels\n\n# 0 ~ 1사이값 float32로 변경하는 함수 호출 한 뒤 OHE 적용 \ndef get_preprocessed_ohe(images, labels):\n    images, labels = get_preprocessed_data(images, labels)\n    # OHE 적용 \n    oh_labels = to_categorical(labels)\n    return images, oh_labels\n\n(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n\ntrain_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\ntest_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\nprint(train_images.shape, train_oh_labels.shape, test_images.shape, test_oh_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T07:51:16.393512Z","iopub.execute_input":"2022-04-13T07:51:16.393772Z","iopub.status.idle":"2022-04-13T07:51:31.875826Z","shell.execute_reply.started":"2022-04-13T07:51:16.393742Z","shell.execute_reply":"2022-04-13T07:51:31.875082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam , RMSprop \nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n\ninput_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n\n#x = Conv2D(filters=32, kernel_size=(5, 5), padding='valid', activation='relu')(input_tensor)\nx = Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu', kernel_initializer='he_normal')(input_tensor)\nx = Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu', kernel_initializer='he_normal')(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\n\nx = Conv2D(filters=64, kernel_size=3, padding='same', activation='relu', kernel_initializer='he_normal')(x)\nx = Conv2D(filters=64, kernel_size=3, padding='same', kernel_initializer='he_normal')(x)\nx = Activation('relu')(x)\nx = MaxPooling2D(pool_size=2)(x)\n\nx = Conv2D(filters=128, kernel_size=3, padding='same', activation='relu', kernel_initializer='he_normal')(x)\nx = Conv2D(filters=128, kernel_size=3, padding='same', activation='relu', kernel_initializer='he_normal')(x)\nx = MaxPooling2D(pool_size=2)(x)\n\n# cifar10의 클래스가 10개 이므로 마지막 classification의 Dense layer units갯수는 10\nx = Flatten(name='flatten')(x)\nx = Dropout(rate=0.5)(x)\nx = Dense(300, activation='relu', name='fc1')(x)\nx = Dropout(rate=0.3)(x)\noutput = Dense(10, activation='softmax', name='output')(x)\n\nmodel = Model(inputs=input_tensor, outputs=output)\n\nmodel.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport random as python_random\n\nnp.random.seed(2021)\npython_random.seed(2021)\ntf.random.set_seed(2021)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T07:49:05.443433Z","iopub.execute_input":"2022-04-13T07:49:05.443946Z","iopub.status.idle":"2022-04-13T07:49:09.031861Z","shell.execute_reply.started":"2022-04-13T07:49:05.443826Z","shell.execute_reply":"2022-04-13T07:49:09.031106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam , RMSprop \nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n\nIMAGE_SIZE=32\ninput_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n\n#x = Conv2D(filters=32, kernel_size=(5, 5), padding='valid', activation='relu')(input_tensor)\nx = Conv2D(filters=32, kernel_size=(3, 3), padding='same')(input_tensor)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\n\nx = Conv2D(filters=32, kernel_size=(3, 3), padding='same')(x)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\n\nx = Conv2D(filters=64, kernel_size=3, padding='same')(x)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\n\nx = Conv2D(filters=64, kernel_size=3, padding='same')(x)\nx = Activation('relu')(x)\nx = Activation('relu')(x)\nx = MaxPooling2D(pool_size=2)(x)\n\nx = Conv2D(filters=128, kernel_size=3, padding='same')(x)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\n\nx = Conv2D(filters=128, kernel_size=3, padding='same')(x)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nx = MaxPooling2D(pool_size=2)(x)\n\n# cifar10의 클래스가 10개 이므로 마지막 classification의 Dense layer units갯수는 10\nx = Flatten(name='flatten')(x)\nx = Dropout(rate=0.5)(x)\nx = Dense(300, activation='relu', name='fc1')(x)\nx = Dropout(rate=0.3)(x)\noutput = Dense(10, activation='softmax', name='output')(x)\n\nmodel = Model(inputs=input_tensor, outputs=output)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T07:49:47.547245Z","iopub.execute_input":"2022-04-13T07:49:47.547514Z","iopub.status.idle":"2022-04-13T07:49:49.681236Z","shell.execute_reply.started":"2022-04-13T07:49:47.547485Z","shell.execute_reply":"2022-04-13T07:49:49.680515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(x=train_images,y=train_oh_labels,batch_size=64,epochs=30,validation_split=0.15)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T07:51:38.166391Z","iopub.execute_input":"2022-04-13T07:51:38.166659Z","iopub.status.idle":"2022-04-13T07:55:02.141924Z","shell.execute_reply.started":"2022-04-13T07:51:38.166628Z","shell.execute_reply":"2022-04-13T07:55:02.141105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(test_images, test_oh_labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T07:55:02.143786Z","iopub.execute_input":"2022-04-13T07:55:02.144178Z","iopub.status.idle":"2022-04-13T07:55:03.523304Z","shell.execute_reply.started":"2022-04-13T07:55:02.144138Z","shell.execute_reply":"2022-04-13T07:55:03.522602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model.predict(np.expand_dims(test_images[0],axis=0))\npredicted_class = np.argmax(preds,axis=1)\nprint(predicted_class)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T07:57:57.705184Z","iopub.execute_input":"2022-04-13T07:57:57.705726Z","iopub.status.idle":"2022-04-13T07:57:57.914166Z","shell.execute_reply.started":"2022-04-13T07:57:57.705689Z","shell.execute_reply":"2022-04-13T07:57:57.912729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport random as python_random\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\n# seed 를 설정해서 학습시마다 동일한 결과 유도. 불행히도 의도한 대로 동작하지 않음. \ndef set_random_seed(seed_value):\n    np.random.seed(seed_value)\n    python_random.seed(seed_value)\n    tf.random.set_seed(seed_value)\n\n# 0 ~ 1사이값의 float32로 변경하는 함수\ndef get_preprocessed_data(images, labels):\n    \n    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n    images = np.array(images/255.0, dtype=np.float32)\n    labels = np.array(labels, dtype=np.float32)\n    \n    return images, labels\n\n# 0 ~ 1사이값 float32로 변경하는 함수 호출 한 뒤 OHE 적용 \ndef get_preprocessed_ohe(images, labels):\n    images, labels = get_preprocessed_data(images, labels)\n    # OHE 적용 \n    oh_labels = to_categorical(labels)\n    return images, oh_labels\n\n# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환 \ndef get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경 및 OHE 적용. \n    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n    \n    # 학습 데이터를 검증 데이터 세트로 다시 분리\n    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n    \n    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels ) \n","metadata":{"execution":{"iopub.status.busy":"2022-04-13T08:10:09.924205Z","iopub.execute_input":"2022-04-13T08:10:09.924487Z","iopub.status.idle":"2022-04-13T08:10:09.936468Z","shell.execute_reply.started":"2022-04-13T08:10:09.924456Z","shell.execute_reply":"2022-04-13T08:10:09.935024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.datasets import cifar10\n\nset_random_seed(2021)\n(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n(tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T08:10:16.350571Z","iopub.execute_input":"2022-04-13T08:10:16.350829Z","iopub.status.idle":"2022-04-13T08:10:18.138172Z","shell.execute_reply.started":"2022-04-13T08:10:16.350799Z","shell.execute_reply":"2022-04-13T08:10:18.137296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input,Dense,Conv2D,Dropout,Flatten,Activation,MaxPooling2D,GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n\ndef create_model():\n    \n    input_tensor = Input(shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n    \n    x = Conv2D(filters=32,kernel_size=3, padding='same')(input_tensor)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    x = Conv2D(filters=32,kernel_size=3,padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D(pool_size=(2,2))(x)\n    \n    x = Conv2D(filters=64, kernel_size=3, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(filters=64, kernel_size=3, padding='same')(x)\n    x = Activation('relu')(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D(pool_size=2)(x)\n    \n    x = Conv2D(filters=128, kernel_size=3, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(filters=128, kernel_size=3, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D(pool_size=2)(x)\n    \n    x = Flatten(name = 'flatten')(x)\n    x = Dropout(rate=0.5)(x)\n    x = Dense(300, activation='relu',name='fc1')(x)\n    x = Dropout(rate=0.3)(x)\n    output = Dense(10,activation='softmax',name='output')(x)\n    \n    \n    model = Model(inputs = input_tensor, outputs=output)\n    model.summary()\n    \n    return model\n","metadata":{"execution":{"iopub.status.busy":"2022-04-13T08:20:04.415358Z","iopub.execute_input":"2022-04-13T08:20:04.415642Z","iopub.status.idle":"2022-04-13T08:20:04.429853Z","shell.execute_reply.started":"2022-04-13T08:20:04.41561Z","shell.execute_reply":"2022-04-13T08:20:04.428995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = create_model()\nmodel.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n\nnoshuffle_history = model.fit(x=tr_images, y=tr_oh_labels, batch_size=64, epochs=30,shuffle=False,validation_data=(val_images, val_oh_labels))\nevaluation_result = model.evaluate(test_images, test_oh_labels, batch_size=64)\n\nprint(evaluation_result)\n\ntf.keras.backend.clear_session()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T08:20:11.491318Z","iopub.execute_input":"2022-04-13T08:20:11.49158Z","iopub.status.idle":"2022-04-13T08:22:43.046239Z","shell.execute_reply.started":"2022-04-13T08:20:11.491549Z","shell.execute_reply":"2022-04-13T08:22:43.045511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=create_model()\nmodel.compile(optimizer=Adam(), loss='categorical_crossentropy',metrics=['accuracy'])\nshuffle_history = model.fit(x=tr_images, y=tr_oh_labels, batch_size=64, epochs=30, shuffle=True, \n                    validation_data=(val_images, val_oh_labels))\nevaluation_result = model.evaluate(test_images, test_oh_labels, batch_size=64)\nprint('#### 테스트 세트로 evaluation 결과 :', evaluation_result)\n\ntf.keras.backend.clear_session()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T08:25:07.97865Z","iopub.execute_input":"2022-04-13T08:25:07.979024Z","iopub.status.idle":"2022-04-13T08:27:39.699356Z","shell.execute_reply.started":"2022-04-13T08:25:07.978983Z","shell.execute_reply":"2022-04-13T08:27:39.698653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\ndef show_history_shuffle(noshuffle_history, shuffle_history):\n    figure, axs = plt.subplots(nrows=1, ncols=2, figsize=(16,4))\n    \n    axs[0].plot(noshuffle_history.history['val_accuracy'],label='no shuffle acc')\n    axs[0].plot(shuffle_history.history['val_accuracy'],label='shuffle acc')\n    \n    axs[1].plot(noshuffle_history.history['val_loss'],label='no shuffle loss')\n    axs[1].plot(shuffle_history.history['val_loss'],label='shuffle loss')\n    axs[0].legend()\n    axs[1].legend()\n    \nshow_history_shuffle(noshuffle_history, shuffle_history)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T08:27:41.978439Z","iopub.execute_input":"2022-04-13T08:27:41.978695Z","iopub.status.idle":"2022-04-13T08:27:42.343333Z","shell.execute_reply.started":"2022-04-13T08:27:41.978667Z","shell.execute_reply":"2022-04-13T08:27:42.342658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"b_sizes=[32,64,256,512]\nhistories = []\nevaluations = []\n\nfor b_size in b_sizes:\n    model = create_model()\n    model.compile(optimizer=Adam(),loss='categorical_crossentropy',metrics=['accuracy'])\n    history = model.fit(x=tr_images, y=tr_oh_labels, batch_size=b_size, epochs=30, shuffle=True,validation_data=(val_images, val_oh_labels))\n    histories.append(history)\n    \n    evaluation_result=model.evaluate(test_images,test_oh_labels, batch_size=b_size)\n    evaluations.append(evaluation_result)\n    \n    tf.keras.backend.clear_session()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T09:33:23.008264Z","iopub.execute_input":"2022-04-13T09:33:23.008777Z","iopub.status.idle":"2022-04-13T09:33:23.042024Z","shell.execute_reply.started":"2022-04-13T09:33:23.008698Z","shell.execute_reply":"2022-04-13T09:33:23.040614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\ndef show_history_batch(histories):\n    figure, axs = plt.subplots(nrows=1, ncols=2, figsize=(16, 4))  \n    # batch 크기별 validation accuracy 비교 \n    axs[0].plot(histories[0].history['val_accuracy'], label='batch 32 acc')\n    axs[0].plot(histories[1].history['val_accuracy'], label='batch 64 acc')\n    axs[0].plot(histories[2].history['val_accuracy'], label='batch 256 acc')\n    axs[0].plot(histories[3].history['val_accuracy'], label='batch 512 acc')\n    \n    # batch 크기별 validation loss 비교\n    axs[1].plot(histories[0].history['val_loss'], label='batch 32 loss')\n    axs[1].plot(histories[1].history['val_loss'], label='batch 64 loss')\n    axs[1].plot(histories[2].history['val_loss'], label='batch 256 loss')\n    axs[1].plot(histories[3].history['val_loss'], label='batch 512 loss')\n    \n    axs[0].legend()\n    axs[1].legend()\n\nshow_history_batch(histories)","metadata":{},"execution_count":null,"outputs":[]}]}